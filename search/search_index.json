{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"main/","title":"About this document","text":"<p>  To the extent possible under law, the authors have waived all    copyright and related or neighboring rights to this document. For details,    please refer to the Creative Commons <code>CC0</code> license <sup>2</sup>.    This work is published from: CERN, Geneva. </p>"},{"location":"main/#introduction","title":"Introduction","text":"<p>This section is non-normative. </p> <p>It is widely agreed upon that the publication of likelihood models from high energy physics experiments is imperative for the preservation and public access to these results. Detailed arguments have been made elsewhere already <sup>3</sup>. This document sets out to provide a standardized format to publish and archive statistical models of any size and across a wide range of mathematical formalisms in a way that is readable by both humans and machines.  With the introduction of <code>pyhf</code> <sup>4</sup><sup>5</sup>, a <code>JSON</code> format for likelihood serialization has been put forward. However, an interoperable format that encompasses likelihoods with a scope beyond stacks of binned histograms was lacking. With the release of <code>ROOT</code> 6.26/00 <sup>6</sup> and the experimental <code>RooJSONFactoryWSTool</code> therein, this gap has now been filled.  This document sets out to document the syntax and features of the Statistics Serialization Standard (HS<sup>3</sup>) for likelihoods and statistical models in general, as to be adopted by any HS<sup>3</sup>-compatible statistics framework. The examples in this document employ the <code>JSON</code> notation, but are intended to encompass also representations as <code>YAML</code> or <code>TOML</code>. </p>"},{"location":"main/#how-to-use-this-document","title":"How to use this document","text":"<p>Developers of statistical toolkits are invited to specifically refer to versions of this document relating to the support of this standard in their respective implementations.  Please note that this document as well as the HS<sup>3</sup> standard are still in development and can still undergo minor and major changes in the future. This document describes the syntax of HS<sup>3</sup> v0.2.9. </p>"},{"location":"main/#sec:hs3-semantics","title":"Statistical semantics of HS<sup>3</sup>","text":""},{"location":"main/#sec:models-and-parameters","title":"Statistical models, probability distributions and parameters","text":"<p>HS<sup>3</sup> takes a \"forward-modelling\" approach throughout: a statistical model \\(m\\) maps a space \\(\\Theta\\) of free parameters \\(\\theta\\) to a space of probability distributions that describe the possible outcomes of a specific experiment. For any given parameters \\(\\theta\\), the model returns a concrete probability distribution \\(m(\\theta)\\). Observed data \\(x\\) is then treated as random variate, presumed to be drawn from the model: \\(x \\sim m(\\theta)\\).  Parameters in HS<sup>3</sup> are always named, so semantically the elements of a parameter space \\(\\Theta\\) are named tuples \\(\\theta\\) (meaning tuples in which every entry has a name). Even if there is only a single free parameter, \\(\\theta\\) should be thought of as a single-entry named tuple. In the current version of this standard, parameter tuples must be flat and only consist of real numbers, vector-valued or nested entries are not supported yet. Future versions of the standard will likely be less restrictive, especially with respect to discrete or vector-valued parameters. Parameter domains defined as part of this standard may be of various types, even though the current version only supports product domains. Future versions are likely to be less restrictive in this regard.  Mathematically and computationally, it is often convenient to treat parameters as flat real-valued vectors instead of named tuples, it is the responsibility of the implementation to map between these different views of parameters when and where necessary.  Probability distributions in HS<sup>3</sup> (see  Distributions) are typically parameterized. Any instance of a distribution that has some of its parameters bound to names instead of concrete values, e.g. \\(m = d_{\\mu = a, \\sigma = 0.7, \\lambda = b, ...}\\), constitutes a valid statistical model \\(m(\\theta)\\) with model parameters \\(\\theta = (a, b)\\).  When probability distributions are combined via a Cartesian product (see  Product distribution), then the named tuples that contain their free parameter values are concatenated. So \\(m = d_{\\mu = a, \\sigma = b} \\times d_{\\mu = c, \\sigma = 0.7}\\) constitutes a model \\(m(\\theta)\\) with model parameters \\(\\theta = (a, b, c)\\).  Distribution parameters may also be bound to the output of functions, and if those functions have inputs that are bound to names instead of values (or again bound to such functions, recursively), then those names become part of the model parameters. A configuration \\(m = d_{\\mu = a, \\sigma = 0.7, \\lambda = f}, f = \\texttt{sum}(4.2, g), g = \\texttt{sum}(1.3, b)\\), for example, also constitutes a (different) model \\(m(\\theta)\\) with parameters \\(\\theta = (a, b, c)\\).  If all parameter values of a probability distribution are set to concrete values, so if there are not directly (or indirectly via functions) bound to names, we call this probability distribution a concrete distribution here. Such distributions can be used as Bayesian  priors (see Bayesian inference).  The variates of all distributions (so the possible results of random draws from them) are also named tuples in all cases. So even instances of univariate distributions, like the normal distributions, have variates like \\((x = \\ldots)\\). The names in the variate tuples can be configured for each instance of a distribution, and must be unique across all distributions that are used together in a model. In Cartesian products of distributions, their variate tuples are concatenated. As with parameter tuples, nested tuples are not supported. The tuple entries, however, may be vector-valued, in contrast to parameter tuples. </p>"},{"location":"main/#sec:what-is-a-pdf","title":"Probability density functions (PDFs)","text":"<p>Statistics literature often discriminates between probability density functions (PDF) for continuous probability distributions and probability mass functions (PMF) for discrete probability distributions. This standard use the term PDF for both continuous and discrete distributions. The concept of density is to be understood in terms of densities in the realm of measure theory here, that is the density of a probability measure (distribution) is its Radon-Nikodym derivative in respect to an (implied) reference measure.  The choice of reference measure would be arbitrary in principle, which scales likelihood functions  (Sec. Likelihood) by a constant factor that depends on choice of reference. In this standard, a specific reference measures is implied for each probability distribution, typically the Lebesgue measure for continuous distributions and the counting measure for discrete distributions. The standard aims to to match the PDF (resp.\u00a0PMF) most commonly used in literature for each specific probability distribution and the mathematical form of the PDF is documented explicitly for each distribution in the standard. So within HS<sup>3</sup>, probability densities and likelihood functions are unambiguous.  Here we use \\(\\text{PDF}(m(\\theta), x)\\) to denote the density value of the probability distribution/measure \\(m\\), parameterized by \\(\\theta\\), at the point/variate \\(x\\), in respect to the implied reference for \\(m\\). </p>"},{"location":"main/#sec:data-generation","title":"Observed and simulated data","text":"<p>The term data refers here to any collection of values that represents the outcome of an experiment. Data takes the same form as variates of distributions (see  Distributions, i. e.\u00a0named tuple of real values or vectors. To compare given data with a given model, the names and shapes of the data entries must match the variates of the probability distributions \\(m(\\theta)\\) that the model returns for a specific choice of parameters \\(\\theta\\).  This means that given a model \\(m\\) and concrete parameter values \\(\\theta\\), drawing a set of random values from the probability distribution \\(m(\\theta)\\) produces a valid set of simulated observations. Implementations can use this to provide mock-data generation capabilities. </p>"},{"location":"main/#sec:likelihood-definition","title":"Likelihood functions","text":"<p>The concrete probability distribution \\(m(\\theta)\\) that a model \\(m\\) returns for specific parameter values \\(\\theta\\) can be compared to observed data \\(x\\). This gives rise to a likelihood \\(\\mathcal{L}_{m,x}(\\theta) = \\text{PDF}(m(\\theta), x)\\) that is a real-valued function on the parameter space. Multiple distributions/models that describe different modes of observation can be combined with multiple sets of data that cover those modes of observation into a single likelihood (Sec.  [sec:likelihoods]). In addition to using observed data, implementations may provide the option to use random data generated from  the model (see 1.2.3) to check for Monte-Carlo closure. </p>"},{"location":"main/#sec:frequentist-inference","title":"Frequentist parameter inference","text":"<p>The standard method of frequentist inference is the maximum (or, respectively, profile) likelihood method. In the vast majority of cases, the test statistic used here is the likelihood ratio, that is, the ratio of two values of the likelihood corresponding to two different points in parameter space: one that maximizes the likelihood unconditionally, one one that maximizes the likelihood under some condition such as the values of the parameters of interest expected in the absence of a deviation from the null hypothesis. The corresponding building blocks for such an analysis, such as the list of parameters of interest and the likelihood function to be used, are specified in the analysis section of an HS<sup>3</sup> configuration (Sec. Analyses). </p>"},{"location":"main/#sec:bayesian-inference","title":"Bayesian parameter inference","text":"<p>The standard also encompasses the specification of Baysian posterior distributions over parameters by combining (Sec.  Analyses) likelihoods with probabilty distributions that acts the priors. Here concrete distributions are used to describe the prior probability of parameters in addition to parameterized distributions that are used to describe of the probability of observing specific data. </p>"},{"location":"main/#how-to-read-this-document","title":"How to read this document","text":"<p>In the context of this document, any <code>JSON</code> object is referred to as a struct. A key-value-pair inside such a struct is referred to as a component. If not explicitly stated otherwise, all components mentioned are mandatory.  The components located inside the top-level struct are referred to as top-level components.  The keywords optional and required, as well as should and may are used in accordance with IETF requirement levels <sup>7</sup>. </p>"},{"location":"main/#terms-and-types","title":"Terms and Types","text":"<p>This is a list of used types and terms in this document. </p> <ul> <li><code>struct</code>: represented with { }, containing a key:value mapping,     keys are of type <code>string</code>. </li> <li><code>component</code>: key-value pair within a struct </li> <li><code>array</code> array of items (either <code>string</code>s or <code>number</code>s) without keys. Represented with <code>[...]</code>. </li> <li><code>string</code>: references to objects, names and arbitrary information.     Represented with </li> <li><code>number</code>: either floating or integer type values </li> <li><code>boolean</code>: boolean values; they can be encoded as <code>true</code> and <code>false</code> </li> </ul> <p>All <code>struct</code>s defining functions, distributions, parameters, variables, domains, likelihoods, data or parameter points will be referred to as <code>object</code>s. All <code>object</code>s must always have a component <code>name</code> that must be unique among all <code>object</code>s. </p> <p>Within most top-level <code>component</code>s, any one <code>string</code> given as a value to any component should refer to the <code>name</code> of another <code>object</code>, unless explicitly stated otherwise. Top-level <code>component</code>s in which this is not the case are explicitly marked as such. </p>"},{"location":"main/#file-format","title":"File format","text":"<p>HS3 documents are encoded in the JSON format as defined in ISO/IEC 21778:2017 <sup>8</sup>. Implementations may support other serialization formats that support a non-ambiguous mapping to JSON, such as TOML or YAML, in which case they should use a different file extension. </p>"},{"location":"main/#validators","title":"Validators","text":"<p>Future versions of this standard will recommend official validator implementations and schemata. Currently, these have not been finalized. </p>"},{"location":"main/#how-to-get-in-touch","title":"How to get in touch","text":"<p>Visit the GitHub page https://github.com/hep-statistics-serialization-standard/hep-statistics-serialization-standard </p>"},{"location":"main/#sec:toplevel","title":"Top-level components","text":"<p>In the followingc the top-level <code>component</code>s of HS\\(^3\\) and their parameters/arguments are described. Each component is completely optional, but certain components may depend on other components, which should be provided in that case. The only exception is the component <code>metadata</code> containing the version of HS\\(^3\\), which is always required. The supported top-level components are </p> <ul> <li><code>distributions</code>: (optional) array of <code>object</code>s defining distributions </li> <li><code>functions</code>: (optional) array of <code>object</code>s defining mathematical functions </li> <li><code>data</code>: (optional) array of <code>objects</code> defining observed or simulated data </li> <li><code>likelihoods</code>: (optional) array of <code>object</code>s defining combinations of distributions and data </li> <li><code>domains</code>: (optional) array of <code>object</code>s defining domains, describing ranges of parameters </li> <li><code>parameter_points</code>: (optional) array of <code>object</code>s defining parameter points. These may be used as starting points for minimizations or to document best-fit-values or nominal truth values of datasets </li> <li><code>analyses</code>: (optional) array of <code>object</code>s defining suggested analyses to be run on the models in this file </li> <li><code>metadata</code>: required struct containing meta information; HS\\(^3\\) version number (required), authors, paper references, package versions, data/analysis descriptions (optional) </li> <li><code>misc</code>: (optional) struct containing miscellaneous information, e.g. optimizer settings, plotting colors, etc. </li> </ul> <p>In the following each of these are described in more detail with respect to their own structure. </p>"},{"location":"main/#sec:distributions","title":"Distributions","text":"<p>The top-level component <code>distributions</code> contains an array of distributions in struct format. Distributions must be normalized, thus, the letter \\(\\ensuremath{\\mathcal{M}}\\) in the following descriptions will always relate to the normalization of the distribution. The value of \\(\\ensuremath{\\mathcal{M}}\\) is conditional on the current domain. It must be chosen such that the integral of the distribution over the current domain equals one. The implementations might chose to perform this integral using analytical or numerical means.  Each distribution must have the components <code>type</code>, denoting the kind of distribution described, and a component <code>name</code>, which acts as a unique identifier of this distribution among all other named objects. Distributions in general have the following keys:  -   <code>name</code>: custom unique string (required), e.     g.\u00a0<code>my_distribution_of_x</code>  -   <code>type</code>: string (required) that determines the kind of     distribution, e. g.\u00a0<code>gaussian_dist</code>  -   <code>...</code>: each distribution may have components for the     various individual parameters. For example, distributions of type     <code>gaussian_dist</code> have the specific components <code>mean</code>, <code>sigma</code> and     <code>x</code>. In general, these components may be strings as     references to other <code>objects</code>, but may also directly     yield numeric or boolean values. Depending on the parameter and the     type of distribution, they appear either in single item or array     format. </p> Example: Distributions<pre><code>\"distributions\":[\n    { \"name\":\"gauss1\", \"type\":\"gaussian_dist\", \"mean\":1.0, \"sigma\":\"param_sigma\", \"x\":\"param_x\" }, \n    { \"name\":\"exp1\", \"type\":\"exponential_dist\", \"c\":-2, \"x\":\"data_x\" }, \n    ... \n] \n</code></pre> <p>Distributions can be treated either as <code>extended</code> or as non-<code>extended</code> <sup>9</sup>. Some distributions are always extended, others can never be extended, yet others can be used in extended and non-extended scenarios and have a switch selecting between the two. An non-extended distribution is always normalized to the unity. An extended distribution, on the other hand, can yield values larger than unity, where the yield is interpreted as the number of predicted events. That is to say, the distribution is augmented by a factor that is a Poisson constraint term for the total number of events.  In the following, all distributions supported in HS<sup>3</sup> v0.2.9 are listed in detail. Future versions will expand upon this list. </p>"},{"location":"main/#univariate-fundamental-distributions","title":"Univariate fundamental distributions","text":"<p>This section contains univariate fundamental distributions in the sense that they cannot refer to any other distribution -- only to functions, parameters and exactly one variable.  The of the Argus background distribution is defined as </p>"},{"location":"main/#argus-distribution","title":"Argus distribution","text":"\\[ \\begin{aligned} \\text{ArgusPdf}(m, m_0, c, p) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\cdot m \\cdot \\left[ 1 - \\left( \\frac{m}{m_0} \\right)^2 \\right]^p \\cdot \\exp\\left[ c \\cdot \\left(1 - \\left(\\frac{m}{m_0}\\right)^2 \\right) \\right] \\end{aligned}  \\] <p>and describes the ARGUS background shape. </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>argus_dist</code> </li> <li><code>mass</code>: name of the variable \\(m\\) used as mass </li> <li><code>resonance</code>: value or name of the parameter used as resonance \\(m_0\\) </li> <li><code>slope</code>: value or name of the parameter used as slope \\(c\\) </li> <li><code>power</code>: value or name of the parameter used as exponent \\(p\\). </li> </ul> <p>The of a continued Poisson distribution of the variable \\(x\\) is defined as </p>"},{"location":"main/#continued-poisson-distribution","title":"Continued Poisson distribution","text":"\\[ \\begin{aligned} \\text{ContinuedPoissonPdf}(x, \\lambda) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\exp\\left(x \\cdot \\ln \\lambda - \\lambda - \\ln \\Gamma(x+1)\\right), \\end{aligned}  \\] <p>where \\(\\Gamma\\) denotes the Euler Gamma function.  This function is similar the the Poisson distribution (see  Poisson distribution), but can accept non-integer values for \\(x\\). Notably, the differences between the two might be significant for small values of \\(x\\) (below x). Nevertheless, the distribution is useful to deal with datasets with non-integer event counts, such as asimov datasets <sup>10</sup>. </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>poisson_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) (usually referred to as \\(k\\) for the     standard integer case) </li> <li><code>mean</code>: value or name of the parameter used as mean \\(\\lambda\\).  The of a continuous uniform distribution is defined as: </li> </ul>"},{"location":"main/#uniform-distribution","title":"Uniform distribution","text":"\\[ \\begin{aligned} \\text{UniformPdf}(x) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>uniform_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\)  The generalized Asymmetrical Double-Sided Crystall Ball line shape, composed of a Gaussian distribution at the core, connected with two powerlaw distributions describing the lower and upper tails, given by </li> </ul>"},{"location":"main/#crystalball-distribution","title":"CrystalBall distribution","text":"\\[ \\begin{aligned} \\text{CrystalBallPdf}(m;m_0,\\sigma,\\alpha_L,n_L,\\alpha_R,n_R) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\begin{cases} A_L \\cdot (B_L - \\frac{m - m_0}{\\sigma_L})^{-n_L}, &amp; \\mbox{for }\\frac{m - m_0}{\\sigma_L} &lt; -\\alpha_L \\\\ \\exp \\left( - \\frac{1}{2} \\cdot \\left[ \\frac{m - m_0}{\\sigma_L} \\right]^2 \\right), &amp; \\mbox{for }\\frac{m - m_0}{\\sigma_L} \\leq 0 \\\\ \\exp \\left( - \\frac{1}{2} \\cdot \\left[ \\frac{m - m_0}{\\sigma_R} \\right]^2 \\right), &amp; \\mbox{for }\\frac{m - m_0}{\\sigma_R} \\leq \\alpha_R \\\\ A_R \\cdot (B_R + \\frac{m - m_0}{\\sigma_R})^{-n_R}, &amp; \\mbox{otherwise}, \\\\ \\end{cases} \\end{aligned}  \\] <p>where </p> \\[ \\begin{aligned} A_i &amp;= \\left(\\frac{n_i}{\\left| \\alpha_i \\right|}\\right)^{n_i} \\cdot \\exp\\left(- \\frac {\\left| \\alpha_i \\right|^2}{2}\\right) \\\\ B_i &amp;= \\frac{n_i}{\\left| \\alpha_i \\right|}  - \\left| \\alpha_i \\right| \\\\ \\end{aligned}  \\] <p>The keys are </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>crystalball_dist</code> </li> <li><code>m</code>: name of the variable \\(m\\) </li> <li><code>m0</code>: name or value of the central value \\(m_0\\) </li> <li><code>alpha</code>: value or names of \\(\\alpha_L\\) and \\(\\alpha_R\\) from above.     must not be used in conjuction with <code>alpha_L</code> or     <code>alpha_R</code>. </li> <li><code>alpha_L</code>: value or names of \\(\\alpha_L\\) from above. must     not be used in conjuction with <code>alpha</code>. </li> <li><code>alpha_R</code>: value or names of \\(\\alpha_R\\) from above. must     not be used in conjuction with <code>alpha</code>. </li> <li><code>n</code>: value or names of \\(n_L\\) and \\(n_R\\) from above. must     not be used in conjuction with <code>n_L</code> or <code>n_R</code>. </li> <li><code>n_L</code>: value or names of \\(n_L\\) from above. must not be     used in conjuction with <code>n</code>. </li> <li><code>n_R</code>: value or names of \\(n_R\\) from above. must not be     used in conjuction with <code>n</code>. </li> <li><code>sigma</code>: value or names of \\(\\sigma_L\\) and \\(\\sigma_R\\) from above.     must not be used in conjuction with <code>sigma_L</code> or     <code>sigma_R</code>. </li> <li><code>sigma_L</code>: value or names of \\(\\sigma_L\\) from above. must     not be used in conjuction with <code>sigma</code>. </li> <li><code>sigma_R</code>: value or names of \\(\\sigma_R\\) from above. must     not be used in conjuction with <code>sigma</code>. </li> </ul>"},{"location":"main/#exponential-distribution","title":"Exponential distribution","text":"\\[ \\begin{aligned} \\text{ExponentialPdf}(x, c) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\cdot \\exp(-c\\cdot x) \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>exponential_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>c</code>: value or name of the parameter used as coefficient \\(c\\).  The of a Gaussian/Normal distribution is defined as </li> </ul>"},{"location":"main/#gaussian-normal-distribution","title":"Gaussian Normal distribution","text":"\\[ \\begin{aligned} \\text{GaussianPdf}(x, \\mu, \\sigma) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\exp\\left(\\frac{(x-\\mu)^2}{\\sigma^2}\\right) \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>gaussian_dist</code> or <code>normal_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>mean</code>: value or name of the parameter used as mean value \\(\\mu\\) </li> <li><code>sigma</code>: value or name of the parameter encoding the standard     deviation \\(\\sigma\\).  The of the log-normal distribution is defined as </li> </ul>"},{"location":"main/#log-normal-distribution","title":"Log-Normal distribution","text":"\\[ \\begin{aligned} \\text{LogNormalPdf}(x, \\mu, \\sigma) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}} \\frac{1}{ x } \\exp\\left( -\\frac{(\\ln(x)-\\mu)^2}{2\\sigma^2}\\right) \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>lognormal_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>mu</code>: value or name of the parameter used as \\(\\mu\\) </li> <li><code>sigma</code>: value or name of the parameter \\(\\sigma\\) describing the     shape </li> </ul>"},{"location":"main/#dist:poisson","title":"Poisson distribution","text":"<p>The Poisson distribution of the variable \\(x\\) is defined as </p> \\[ \\begin{aligned} \\text{PoissonPdf}(x, \\lambda) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\frac{\\lambda^x}{x!}  \\text{e}^{-\\lambda}. \\end{aligned}  \\] <p>where \\(x\\) is required to be an integer.  In this case, the behavior for non-integer values of \\(x\\) is undefined.  -   <code>name</code>: custom unique string  -   <code>type</code>: <code>poisson_dist</code>  -   <code>x</code>: name of the variable \\(x\\) (usually referred to as \\(k\\) for the     standard integer case)  -   <code>mean</code>: value or name of the parameter used as mean \\(\\lambda\\).  The of a polynomial distribution is defined as </p>"},{"location":"main/#polynomial-distribution","title":"Polynomial distribution","text":"\\[ \\begin{aligned} \\text{PolynomialPdf}(x, a_0, a_1, a_2, ...) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\sum_{i=0}^n a_i x^i = a_0 + a_1 x + a_2 x^2 + ... \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>polynomial_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>coefficients</code>: array of coefficients \\(a_i\\). The length of this     array implies the degree of the polynomial. </li> </ul>"},{"location":"main/#multivariate-fundamental-distributions","title":"Multivariate fundamental distributions","text":"<p>This section contains multivariate fundamental distributions. They may refer to functions, parameters and more than one variable.  This distributions represents a product of Poisson distributions defining the statistical uncertainties of the histogram templates defined in a <code>histfactory_func</code>. </p>"},{"location":"main/#barlow-besston-lite-constraint-distribution","title":"Barlow-Besston-Lite Constraint distribution","text":"\\[ \\begin{aligned} \\text{BarlowBeestonLitePoissonConstraintPdf}(x) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}} \\prod_i^n \\text{PoissonPdf}(x_i\\cdot \\tau_i,\\tau_i) \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>barlow_beeston_lite_poisson_constraint_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>expected</code>: array of central values \\(\\tau_i\\)  The of the multivariate normal distribution is defined as </li> </ul>"},{"location":"main/#multivariate-normal-distribution","title":"Multivariate normal distribution","text":"\\[ \\begin{aligned} \\text{MvNormalPdf}(\\mathbf{x}, \\boldsymbol\\mu, \\boldsymbol\\Sigma) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}} \\exp \\left( -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol\\mu)^{\\!\\mathsf{T}} \\boldsymbol\\Sigma^{-1}(\\mathbf{x} - \\boldsymbol\\mu) \\right), \\end{aligned}  \\] <p>with \\(\\boldsymbol\\Sigma \\in \\mathbb{R}^{k\\times k}\\) being positive-definite. </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>multivariate_normal_dist</code> </li> <li><code>x</code>: array of names of the variables \\(\\mathbf{x}\\). This also     includes mixed arrays of values and names. </li> <li><code>mean</code>: array of length \\(k\\) of values or names of the parameters     used as mean values \\(\\boldsymbol\\mu\\) </li> <li><code>covariances</code>: an array comprised of \\(k\\) sub-arrays, each of which     is also of length \\(k\\), designed to store values or names of the     entries of the covariance matrix \\(\\boldsymbol\\Sigma\\). In general,     the covariance matrix \\(\\boldsymbol\\Sigma\\) must be     symmetric and positive semi-definite. </li> </ul> <p>Note: Users should prefer the specific distributions defined in this standard over generic distributions where possible, as implementations of these will typically be more optimized. Generic distributions should only be used if no equivalent specific distribution is defined. </p> <p>A generic distribution is defined by an expression that respresents the PDF of the distribution in respect to the Lebesque measure. The expression must be a valid HS<sup>3</sup>-expression string (see Section  Generic Expressions). </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>generic_dist</code> </li> <li><code>expression</code>: a string with a generic mathematical expression.     Simple mathematical syntax common to most programming languages     should be used here, such as <code>x-2*y+z</code>. The arguments <code>x</code>, <code>y</code> and     <code>z</code> in this example must be parameters, functions or     variables.  The distribution is normalized by the implementation, a normalization term should not be included in the expression. If the expression results in a negative value, the behavior is undefined. </li> </ul>"},{"location":"main/#histfactory-distribution","title":"HistFactory distribution","text":"<p>HistFactory <sup>11</sup> is a language to describe statistical models consisting only of \"histograms\" (which is used interchangeably with \"step-functions\" in this context). Each HistFactory distribution describes one \"channel\" or \"region\" of a binned measurement, containing a stack of \"samples\", i. e.\u00a0binned distributions sharing the same binning (step-functions describing the signal or background of a measurement). Such a HistFactory model is shown in Figure 1 (originally from  <sup>12</sup>). Each of the contributions may be subject to <code>modifiers</code>. </p> <p> </p> <p>The prediction for a binned region is given as </p> \\[ \\begin{aligned} \\lambda(x)=\\sum_{s\\in\\text{samples}} \\left[ \\left( d_s(x) + \\sum_{\\delta\\in M_{\\delta}} \\delta(x,\\theta_\\delta) \\right) \\prod_{\\kappa\\in M_\\kappa} \\kappa(x,\\theta_\\kappa)   \\right] \\end{aligned}  \\] <p>Here \\(d_s(x)\\) is the prediction associated with the sample \\(s\\), a step function </p> \\[ \\begin{aligned} d_s(x) = \\chi^{y_s}_{b}(x) \\end{aligned}  \\] <p>In this section, \\(\\chi^{y_s}_{b}(x)\\) denotes a generic step function in the binning \\(b\\) such that \\(\\chi_{b}(x) = y_{s,i}\\), some constant, if \\(x\\in[b_i,b_{i+1})\\). The \\(y_{s,i}\\) in this case are the bin contents (yields) of the histograms.  The \\(M_\\kappa\\) are the multiplicative modifiers, the \\(M_\\delta\\) are the additive modifiers. Each of the modifiers is either multiplicative (\\(\\kappa\\)) or additive (\\(\\delta\\)). All samples and modifiers share the same binning \\(b\\).  The modifiers depend on a set of nuisance parameters \\(\\theta\\), where each modifier can only depend on one \\(\\theta_i\\), but the \\(\\theta_i\\) can take the form of vectors and the same \\(\\theta_i\\) can be shared by several modifiers. By convention, these are denoted \\(\\alpha\\) if they affect all bins in a correlated way, and \\(\\gamma\\) if they affect only one bin at a time. The types of modifiers are </p> <ul> <li>A uncorrelated shape systematic or <code>shapefactor</code> modifier is a     multiplicative modifier that scales each single bin by the value of     some independent parameter \\(\\gamma\\). Here, \\(\\theta_i=\\vec{\\gamma}\\),     where the length of \\(\\vec{\\gamma}\\) is equal to the number of bins in     this region. This type of modifier is sometimes called <code>shapesys</code>,     with some nuance in the meaning. However, both are synonymous in the     context of this standard. </li> <li>A correlated shape systematic or <code>histosys</code> modifier is an     additive modifier that adds or subtracts a constant step function     \\(\\chi^f\\), scaled with a single factor \\(\\alpha\\). The modifier     contains a <code>data</code> section, which contains the subsections     \\(\\texttt{hi}\\) and \\(\\texttt{lo}\\) that help to define the step     function \\(\\chi^f\\). They contain <code>contents</code>, which define the     bin-wise additions or subtractions for \\(\\alpha=1\\). Here,     \\(\\theta_i=\\alpha\\). </li> <li>A normalization systematic or <code>normsys</code> modifier is a     multiplicative modifier that scales the entire sample with the same     constant factor \\(f\\) that is a function of \\(\\alpha\\). The modifier     contains a <code>data</code> section, which contains the values \\(\\texttt{hi}\\)     and \\(\\texttt{lo}\\) that help to define \\(f\\). There are different     functional forms that can be chosen for \\(f\\). However, by convention     \\(f(\\alpha=0)=1\\), \\(f(\\alpha=+1)=\\)\"<code>hi</code>\" and     \\(f(\\alpha=-1)=\\)\"<code>lo</code>\". In this case, \\(\\theta_i=\\alpha\\). </li> <li>A normalization factor or <code>normfactor</code> modifier is a     multiplicative modifier that scales the entire sample in this region     with the value of the parameter \\(\\mu\\) itself. In this case,     \\(\\theta_i=\\mu\\). </li> <li>The <code>staterror</code> modifier is a shorthand for encoding uncorrelated     statistical uncertainties on the values of the step-functions, using     a variant<sup>1</sup> of the Barlow-Beeston Method <sup>13</sup>. Here,     the relative uncertainty on the sum of all samples in this region     containing the <code>staterror</code> modifier is computed bin-by-bin. Then, a     constrained uncorrelated shape systematic (<code>shapesys</code>) is created,     encoding these relative uncertainties in the corresponding <code>Poisson</code>     (or <code>Gaussian</code>) constraint term. </li> </ul> <p>The different modifies and their descriptions are also summarized in the following table: </p> Type of Modifier Description Definition Free Parameters Number of Free Parameters <code>histosys</code> Correlated Shape systematic \\(\\delta(x,\\alpha) = \\alpha * \\chi_b^f\\) \\(\\alpha\\) 1 <code>normsys</code> Normalization systematic \\(\\kappa(x,\\alpha) = f(\\alpha)\\) \\(\\alpha\\) 1 <code>normfactor</code> Normalization factor \\(\\kappa(x,\\mu) = \\mu\\) \\(\\mu\\) 1 <code>shapefactor</code>, <code>staterror</code> Shape factor \\(\\kappa(x,\\vec{\\gamma}) = \\chi_b^{\\gamma}\\) \\(\\gamma_0\\), ..., \\(\\gamma_n\\) #bins <p>The <code>staterror</code> modifier is a special subtype of <code>shapefactor</code>, where the mean of the constraint is given as the sum of the predictions of all the samples carrying a <code>staterror</code> modifier in this bin.  The way modifiers affect the yield in the corresponding bin is subject to an interpolation function. The <code>overallsys</code> and <code>histosys</code> modifiers thus allow for an additional key <code>interpolation</code>, which identifies one of the following functions: </p> <ul> <li><code>lin</code>: \\(\\begin{cases}     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{high}} - y_{\\textit{nominal}}) \\text{ if } x\\geq0\\\\     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{nominal}} - y_{\\textit{low}}) \\text{ if } x&lt;0     \\end{cases}\\) </li> <li><code>log</code>: \\(\\begin{cases}     y_{\\textit{nominal}} \\cdot \\left(\\frac{y_{\\textit{high}}}{y_{\\textit{nominal}}}\\right)^x \\text{ if } x\\geq0\\\\     y_{\\textit{nominal}} \\cdot \\left(\\frac{y_{\\textit{low}}}{y_{\\textit{nominal}}}\\right)^{-x}\\text{ if } x&lt;0     \\end{cases}\\) </li> <li><code>parabolic</code>: \\(\\begin{cases}     y_{\\textit{nominal}} + (2s+d)\\cdot(x-1)+(y_{\\textit{high}} - y_{\\textit{nominal}}) \\text{ if } x&gt;1\\\\     y_{\\textit{nominal}} - (2s-d)\\cdot(x+1)+(y_{\\textit{low}} - y_{\\textit{nominal})}\\text{ if } x&lt;-1\\\\     s \\cdot x^2 + d\\cdot x  \\text{ otherwise}     \\end{cases}\\)\\     with     \\(s=\\frac{1}{2}(y_{\\textit{high}} + y_{\\textit{low}}) - y_{\\textit{nominal}}\\)     and \\(d=\\frac{1}{2}(y_{\\textit{high}} - y_{\\textit{low}})\\) </li> <li><code>poly6</code>: \\(\\begin{cases}     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{high}} - y_{\\textit{nominal}}) \\text{ if } x&gt;1\\\\     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{nominal}} - y_{\\textit{low}}) \\text{ if } x&lt;-1\\\\     y_{\\textit{nominal}} + x \\cdot (S + x \\cdot A \\cdot (15 + x^2 \\cdot (3x^2-10))) \\text{ otherwise}     \\end{cases}\\)\\     with \\(S = \\frac{1}{2}(y_{\\textit{high}} - y_{\\textit{low}})\\) and     \\(A=\\frac{1}{16}(y_{\\textit{high}} + y_{\\textit{low}} - 2\\cdot y_{\\textit{nominal}})\\) </li> </ul> <p>Modifiers can be constrained. This is indicated by the component <code>constraint</code>, which identifies the type of the constraint term. In essence, the likelihood picks up a penalty term for changing the corresponding parameter too far away from its nominal value. The nominal value is, by convention, defined by the type of constraint, and is 0 for all modifiers of type <code>sys</code> (<code>histosys</code>, <code>normsys</code>) and is 1 for all modifiers of type <code>factor</code> (<code>normfactor</code>, <code>shapefactor</code>). The strength of the constraint is always such that the standard deviation of constraint distribution is \\(1\\). </p> <p>The supported constraint distributions, also called constraint types, are <code>Gauss</code> for a gaussian with unit width (a gaussian distribution with a variance of \\(1\\)), <code>Poisson</code> for a unit Poissonian (e.g. a continous Poissonian with a central value 1), or <code>LogNormal</code> for a unit LogNormal,. If a constraint is given, a corresponding distribution will be considered in addition to the <code>aux_likelihood</code> section of the likelihood, constraining the parameter to its nominal value. </p> <p>An exception to this is provided by the <code>staterror</code> modifier as described above, and the <code>shapesys</code> for which a Poissonian constraint is defined with the central values defined as the squares of the values defined in <code>vals</code>. </p> <p>The components of a HistFactory distribution are: </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>histfactory_yield</code> </li> <li><code>axes</code>: array of structs representing the axes. If given each struct     needs to have the component <code>name</code>. Further,     (optional) components are <code>max</code>, <code>min</code> and <code>nbins</code>,     or, alternatively, <code>edges</code>. The definition of the axes follows the     format for binned data (see Section      Binned Data). </li> <li><code>samples</code>: array of structs containing the samples of this channel.     For details see below.  Struct of one sample: </li> <li><code>name</code>: (optional) custom string, unique within this     function </li> <li><code>data</code>: struct containing the components <code>contents</code> and <code>errors</code>,     depicting the data contents and their errors. Both components are     arrays of the same length. </li> <li><code>modifiers</code>: array of structs with each struct containing a     component <code>type</code> of the modifier, as well as a component <code>parameter</code>     (defining a string) or a component <code>parameters</code> (defining an array     of strings) relating to the name or names of parameters controlling     this modifier. Further (optional) components are     <code>data</code> and <code>constraint</code>, both depending on the type of modifier. For     details on these components, see the description above.  Two modifiers are correlated exactly if they share the same parameters as indicated by <code>parameter</code> or <code>parameters</code>. In such a case, it is mandatory that they share the same constraint term. If this is not the case, the behavior is undefined. </li> </ul> HistFactory<pre><code>{\n  \"name\": \"myAnalysisChannel\",\n  \"type\": \"histfactory_dist\",\n  \"axes\": [ { \"max\": 1.0, \"min\": 0.0, \"name\": \"myRegion\", \"nbins\": 2 } ],\n  \"name\":\"myChannel1\",\n  \"samples\": [\n           {  \"name\": \"mySignal\",\n              \"data\": { \"contents\": [ 0.5, 0.7 ], \"errors\": [ 0.1, 0.1 ] },\n          \"modifiers\": [\n                 { \"parameter\": \"Lumi\", \"type\": \"normfactor\" },\n                 { \"parameter\": \"mu_signal_strength\", \"type\": \"normfactor\" },\n                 { \"constraint\": \"Gauss\", \"data\": { \"hi\": 1.1, \"lo\": 0.9 }, \"parameter\": \"my_normalization_systematic_1\", \"type\": \"normsys\" },\n                 { \"constraint\": \"Poisson\", \"parameters\": [\"gamma_stat_1\",\"gamma_stat_2\"], \"type\": \"staterror\" },\n                 { \"constraint\": \"Gauss\", \"data\": { \"hi\": { \"contents\": [ -2.5, -3.1 ] }, \"lo\": { \"contents\": [ 2.2, 3.7 ] } }, \"parameter\": \"my_correlated_shape_systematic_1\", \"type\": \"histosys\" },\n                 { \"constraint\": \"Poisson\", \"data\": { \"vals\": [ 0.0, 1.2 ] }, \"parameter\": \"my_uncorrelated_shape_systematic_2\", \"type\": \"shapesys\" }\n                   ]\n           },\n               { \"name\": \"myBackground\" ... }\n         ]\n} \n</code></pre>"},{"location":"main/#relativistic-breit-wigner-distribution","title":"Relativistic Breit-Wigner distribution","text":"<p>The describes the lineshape of a resonance studies in the mass spectrum of two particle system. It is assumed that the resonance can decay into a list of channels.  The first channel in the list indicates the system for which mass distribution is modelled. </p> \\[ \\begin{aligned}  \\label{eq:relativistic_breit_wigner_dist} \\text{BreitWignerPDF}(m, m_\\text{BW}) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}}\\frac{m \\Gamma_1(m)}{\\left|m_\\text{BW}^2-m^2 - i m_\\text{BW} \\Gamma(m)\\right|^2} ,\\\\ \\nonumber \\Gamma(m) &amp;= \\sum_i \\Gamma_i(m) ,\\\\ \\nonumber \\end{aligned}  \\] <p>When modelling the mass spectrum, the term \\(m\\) in the numerator of  Eq. (Breit-Wigner) accounts for a jacobian of transformation from \\(m^2\\) to \\(m\\). The width term \\(\\Gamma_1(m)\\) adds for the phase space factor for the channel of interest </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>relativistic_breit_wigner_dist</code> </li> <li><code>mass</code>: name of the mass variable \\(m_\\text{BW}\\) </li> <li><code>channels</code>: list of <code>structs</code> encoding the channels </li> </ul> <p>Each of the channels is defined by the partial width \\(\\Gamma_i(m)\\), given as </p> \\[ \\begin{aligned} \\Gamma_i(m) &amp;= \\Gamma_{\\text{BW},i}  n_{li}^2(m)\\rho_i(m) ,\\\\ \\nonumber \\rho_i(m) &amp;= 2q_i(m)/m ,\\\\ \\nonumber q_i(m) &amp;= \\sqrt{(m^2-(m_{1i}+m_{2i})^2)(m^2-(m_{1i}-m_{2i})^2)} / (2m) ,\\\\ \\nonumber n_{li}(m) &amp;= z_i^{li}(m)   h_{li}(z_i(m)) ,\\\\ \\nonumber z_i(m) &amp;= q_i(m)R_i  \\end{aligned}  \\] <p>The \\(h_l(z)\\) is the standard Blatt-Weisskopf form-factors, \\(h_0^2(z) = 1/(1+z^2)\\), \\(h_1^2(z) = 1/(9+3z^2+z^4)\\), and so on (Eqs.(50.30-50.35) in Ref.\u00a0<sup>14</sup>).\\ The <code>struct</code>s defining the channels should contain the following keys: </p> <ul> <li><code>name</code>: name of the final state (optional) </li> <li><code>Gamma</code>: partial width \\(\\Gamma_{\\text{BW}}\\) of the resonance </li> <li><code>m1</code>: mass \\(m_1\\) of the first particle the resonance decays into     (default value \\(0\\)) </li> <li><code>m2</code>: mass \\(m_2\\) of the second particle the resonance decays into     (default value \\(0\\)) </li> <li><code>l</code>: orbital angular momentum \\(l\\) (default value \\(0\\)) </li> <li><code>R</code>: form-factor size parameter \\(R\\) (default value \\(3\\) GeV)  For non-zero angular momentum, \\(\\Gamma_i(m_\\text{BW})\\) gives an approximation to the partial width of the resonance, not \\(\\Gamma_{\\text{BW},i}\\).  A commonly used approximation of the relativistic Breit-Wigner function with the constant width is a special case of the  Eq. (Breit-Wigner), where the <code>[channels]</code> argument contains a single channel with \\(m_1=0\\), \\(m_2=0\\), and \\(l=0\\). </li> </ul>"},{"location":"main/#composite-distributions","title":"Composite distributions","text":"<p>This section contains composite distributions in the sense that they refer to other distribution which they combine or modify in some way.  The of the mixture distribution, sometimes called additions of distributions, is a (weighted) sum of distributions \\(f_i(\\vec{x})\\), depending on the same variable(s) \\(\\vec{x}\\): </p>"},{"location":"main/#mixture-distribution","title":"Mixture distribution","text":"\\[ \\begin{aligned} \\text{MixturePdf}(x) = \\frac{1}{\\ensuremath{\\mathcal{M}}}\\sum_{i=1}^{n} c_i \\cdot f_i(\\vec{x}) , \\end{aligned}  \\] <p>where the \\(c_i\\) are coefficients and \\(\\vec{x}\\) is the vector of variables. </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>mixture_dist</code> </li> <li><code>name</code>: name of the variable \\(x\\) (optional, since the     variable is fully defined by the summands) </li> <li><code>summands</code>: array of names referencing distributions </li> <li><code>coefficients</code>: array of names of coefficients \\(c_i\\) or numbers to     be added </li> <li><code>extended</code>: boolean denoting whether this is an extended     distribution (optional, as it can be inferred from the     lengths of the lists for <code>summands</code> and <code>coefficients</code>)  This distribution can be treated as extended or as non-extended. </li> <li>If the number of coefficients equals the number of distributions and     'extended' is 'false', then the sum of the coefficient must be     (approximately) one. </li> <li>If the number of coefficients equals the number of distributions and     'extended' is 'true', then the sum of the coefficients will be used     as the Poisson rate parameter and the mixture distribution itself     will use the coefficients normalized by their sum. </li> <li>If the number of coefficients is one less than the number of     distributions, then 'extended' must be 'false' and \\(c_n\\) is computed     from the other coefficients as </li> </ul> \\[ \\begin{aligned}     c_n &amp;= 1 - \\sum_{i=1}^{n-1}c_i .     \\end{aligned}  \\]"},{"location":"main/#sec:product-distribution","title":"Product distribution","text":"<p>The of the product of s of independent distributions \\(f_i\\) is defined as </p> \\[ \\begin{aligned} \\text{ProductPdf}(x) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}}\\prod_i^n f(x). \\end{aligned}  \\] <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>product_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) (optional, since the     variable is fully defined by the factors) </li> <li><code>factors</code>: array of names referencing distributions  A distribution that is specified via a non-normalized density function \\(f(x)\\). Formally, it corresponds to the probability measure that has the density \\(f(x)\\) in respect to the Lebesgue measure.  The density function is normalized automatically by \\(\\ensuremath{\\mathcal{M}}= \\int f(x) dx\\), so the PDF of the distribution is </li> </ul>"},{"location":"main/#density-function-distribution","title":"Density Function distribution","text":"\\[ \\begin{aligned} \\text{DensityFunctionPdf}(f, x) &amp;= \\frac{f(x)}{\\ensuremath{\\mathcal{M}}} \\end{aligned}  \\] <p>The distribution can be specified either via the non-normalized density function \\(f(x)\\) or via the non-normalized log-density function \\(\\log(f(x))\\): </p> <ul> <li><code>density_function\\_dist</code>$: Specified via the PDF \\(f(x)\\) </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>density_function_dist</code> </li> <li><code>function</code>: The density function \\(f\\) </li> <li><code>log_density_function\\_dist</code>: Specified via the PDF     \\(f(x)\\) </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>log_density_function_dist</code> </li> <li><code>function</code>: The density function \\(f\\) </li> </ul>"},{"location":"main/#dist:poisson-point-process","title":"Poisson point process","text":"<p>A Poisson point process distribution is understood here as the distribution of the outcomes of a (typically inhomogeneous) Poisson point process. In particle physics, such a distribution is often called an extended distribution <sup>9</sup>.  In HS<sup>3</sup>, a Poisson point process distribution is specified using a global-rate parameter \\(\\lambda\\) and an underlying distribution \\(m\\), either explicitly or implicitly (see below).  Random values are drawn from the Poisson point process distribution by drawing a random number \\(n\\) from a Poisson distribution of the global-rate \\(\\lambda\\), and then drawing \\(n\\) random values from the underlying distribution \\(m\\). The resulting random values are vectors \\(x\\) of length \\(n\\), so their length varies.  The PDF the Poisson point process distribution at an outcome \\(x\\) (a vector of length \\(n\\)) is </p> \\[ \\begin{aligned} \\text{PoissonPointProcessPdf}(\\lambda, m, x) &amp;= \\text{PoissonPdf}(n, \\lambda) \\cdot \\prod_i^n \\text{PDF}(m, x_i). \\end{aligned}  \\] <p>In particle physics, the function \\(\\text{PoissonPointProcessPdf}(\\lambda, m(\\theta), x)\\), for a fixed observation \\(x\\) and varying parameters \\(\\lambda\\) and \\(\\theta\\), is often called an extended likelihood.  A a poisson point process distribution can be specified in HS<sup>3</sup> in two ways: </p> <ul> <li>`rate_extended_dist$: The global-rate parameter \\(\\lambda\\)     and underlying distribution \\(m\\) are specified explicitly: </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>rate_extended_dist</code> </li> <li><code>rate</code>: The global rate \\(\\lambda\\) </li> <li><code>dist</code>: The underlying distribution \\(m\\) </li> </ul> <p>The name of the variable \\(x\\) is taken from the underlying     distribution. The underlying distribution must not be     referred to from other components of the statistical model. </p> <ul> <li><code>rate_density_dist</code>: Specified via a non-normalized     rate-density function \\(f\\). Both the global-rate parameter and the     underlying distribution are implicit: \\(\\lambda = \\int f(y) d y\\) and     \\(m = \\text{density_function_dist}(f)\\). More formally, the distribution corresponds to the inhomogeneous     Poisson point process that is defined by a non-normalized rate     measure which has density \\(f\\) in respect to the Lebesque measure. </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>rate_density_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>density</code>: The rate-density function \\(f\\) </li> </ul>"},{"location":"main/#dist:bin-counts","title":"Bin count distribution","text":"<p>This is a binned version of the Poisson point process distribution  (Poisson point process). Is is the distribution of the bin counts that result from histogramming the outcomes of a Poisson point process distribution using a given binning scheme (see  Binned Data).  Like the Poisson point process distribution, a Bin-counts distribution can either be specified via a global-rate parameter \\(\\lambda\\) and an underlying distribution \\(m\\), or via a rate-density function \\(f\\) (in which case \\(\\lambda\\) and \\(m\\) are implicit). In addition, the binning scheme also has to be specified in either case, unless it can be inferred (see below).  For \\(k\\) bins, this type of distribution corresponds to a product of \\(k\\) Poisson distributions with rates </p> \\[ \\begin{aligned} \\nu_i &amp;= \\lambda \\cdot \\int_{\\text{bin}_i} \\text{PDF}(y, m) dy \\quad \\text{equivalent to}\\\\ \\nu_i &amp;= \\int_{\\text{bin}_i} f(y) dy \\end{aligned}  \\] <p>The PDF the Bin-counts distribution at an outcome \\(x\\) (a vector of length \\(k\\), same as the number of bins) is </p> \\[ \\begin{aligned} \\text{BinCountsPdf}(x) &amp;= \\prod_i^k \\text{PoissonPdf}(x_i, \\nu_i) \\end{aligned}  \\] <ul> <li><code>bincounts_extended_dist</code>: The global-rate parameter     \\(\\lambda\\) and underlying distribution \\(m\\) are specified explicitly: </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>bincounts_extended_dist</code> </li> <li><code>rate</code>: The global rate \\(\\lambda\\) </li> <li><code>dist</code>: The underlying distribution \\(m\\) </li> <li><code>axes</code>: a definition of the binning to be used, following the         defintions in      Binned data]. optional if <code>dist</code>         is a binned distribution, in which case the same binning is used         by default. </li> </ul> <p>The name of the variable \\(x\\) is taken from the underlying     distribution. The underlying distribution must not be     referred to from other components of the statistical model.  <code>bincounts_density_dist</code>: Specified via a non-normalized     rate-density function \\(f\\). Both the global-rate parameter and the     underlying distribution are implicit: \\(\\lambda = \\int f(y) dy\\) and     \\(m = \\text{density_function_dist}(f)\\). </p> <p>More formally, the distribution corresponds to the inhomogeneous     Poisson point process that is defined by a non-normalized rate     measure which has density \\(f\\) in respect to the Lebesque measure. </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>bincounts_density_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>density</code>: The rate-density function \\(f\\) </li> <li><code>axes</code>: a definition of the binning to be used, following the         defintions in          Binned Data. </li> </ul>"},{"location":"main/#sec:functions","title":"Functions","text":"<p>The top-level component <code>functions</code> describes an array of mathematical functions in struct format to be used as helper objects. Similar to distributions each entry is required to have the components <code>type</code> and <code>name</code>. Other components are dependent on the kind of functions. The field <code>name</code> is required and may be any custom unique string. Functions in general have the following components: </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: string that determines the kind of function, e.g. <code>sum</code> </li> <li><code>...</code>: each function has individual parameter keys for the various     individual parameters. For example, functions of type <code>sum</code> have the     parameter key <code>summands</code>. In general, these keys can describe     strings as references to other objects or numbers. Depending on the     parameter and the type of function, they appear either in single     item or array format. </li> </ul> Example: Functions<pre><code>\"functions\": [ \n    { \"name\" : \"sum1\", \"type\" : \"sum\", \"summands\" : [1.8, 4, \"param_xy\"] }, \n    ... \n    ]\n</code></pre> <p>In the following the implemented functions are described in detail. </p>"},{"location":"main/#product","title":"Product","text":"<p>A product of values or functions \\(a_i\\). </p> \\[ \\begin{aligned} \\text{Prod} &amp;= \\prod_i^n a_i \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>product</code> </li> <li><code>factors</code>: array of names of the elements of the product or numbers. </li> </ul>"},{"location":"main/#sum","title":"Sum","text":"<p>A sum of values or functions \\(a_i\\). </p> \\[ \\begin{aligned} \\text{Sum} &amp;= \\sum_i^n a_i \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>sum</code> </li> <li><code>summands</code>: array of names of the elements of the sum or numbers. </li> </ul>"},{"location":"main/#generic-function","title":"Generic Function","text":"<p>Note: Users should prefer the specific functions defined in this standard over generic functions where possible, as implementations of these will typically be more optimized. Generic functions should only be used if no equivalent specific distribution is defined.  A generic function is defined by an expression. The expression must be a valid HS<sup>3</sup>-expression string (see Section  Generic Expressions). </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>generic_function</code> </li> <li><code>expression</code>: a string with a generic mathematical expression.     Simple mathematical syntax common to programming languages should be     used here, such as <code>x-2*y+z</code>. For any non-elementary operations, the     behavior is undefined. </li> </ul>"},{"location":"main/#sec:data","title":"Data","text":"<p>The top-level component <code>data</code> contains an array of data sets in struct format. Each data set needs to contain the components <code>type</code> and <code>name</code>. Other components are dependent on the type of data set as demonstrated below: </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: string that determines the format of the observations </li> <li><code>...</code>: each type of observations has different parameter keys. Some     of these are optional and marked accordingly in the     more detailed description below  A detailed description of the different types with examples can be found below.  While data, in most settings, has no uncertainty attached to it, this standard does allow to provide data with uncertainty, as there are some settings in which uncorrelated or correlated errors need to be taken into account. These include cases such as </li> <li>generated data obtained from importance sampling, including a     (potentially Gaussian) uncertainty from the frequency weights </li> <li>unfolded data, resulting from arbitrarily complex transformation     functions involving statistical models folding some degree of     uncertainty into the data points themselves  While it should always be preferred to publish \"raw\" data, allowing to include pre-processed data with corresponding uncertainties expands the possible applications considerably. </li> </ul>"},{"location":"main/#point-data","title":"Point Data","text":"<p>Point data describes a measurement of a single number, with a possible uncertainty (error). </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>point</code> </li> <li><code>value</code>: value of this data point </li> <li><code>uncertainty</code>: (optional) uncertainty of this data     point </li> </ul> Example: Point Data<pre><code>\"data\":[ \n    { \n        \"name\":\"data1\", \n        \"type\":\"point\", \n        \"value\":0., \n        \"uncertainty\":1. \n    } \n]\n</code></pre>"},{"location":"main/#unbinned-data","title":"Unbinned Data","text":"<p>Unbinned data describes a measurement of multiple data points in a possibly multi-dimensional space of variables. These data points can be weighted. </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>unbinned</code> </li> <li><code>entries</code>: array of arrays containing the coordinates/entries of the     data </li> <li><code>axes</code>: array of structs representing the axes. Each struct     must have the components <code>name</code> as well as <code>max</code> and     <code>min</code>. </li> <li><code>weights</code>: (optional) array of values containing the     weights of the individual data points, to be used for \\(\\chi^2\\)     comparisons and fits. If this component is not given, weight 1 is     assumed for all data points. If given, the array needs to be of the     same length as <code>entries</code>. </li> <li><code>entries_uncertainties</code>: (optional) array of arrays     containing the errors/uncertainties of each entry. If given, the     array needs to be of the same shape as <code>entries</code>.  Example: Unbinned Data<pre><code>\"data\":[ \n    { \n        \"name\":\"data1\", \n        \"type\":\"unbinned\", \n        \"weights\":[ 9.0, 18.4 ], \n        \"entries\":[ [1,3], [2,9] ], \n        \"entries_uncertainties\":[ [0.3], [0.6] ], \n        \"axes\":[ \n            { \"name\":\"variable1\", \"min\":1, \"max\":3 }, \n            { \"name\":\"variable2\", \"min\":-10, \"max\":10 }, \n            ... \n        ] \n    }, \n    ... \n]\n</code></pre></li> </ul>"},{"location":"main/#sec:binned-data","title":"Binned Data","text":"<p>Binned data describes a histogram of data points with bin contents in a possibly multi-dimensional space of variables. Whether entries that fall precisely on the bin boundaries are sorted into the smaller or larger bin is under the discretion of the creator of the model and thus not defined. </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>binned</code> </li> <li><code>contents</code>: array of values representing the contents of the binned     data set </li> <li><code>axes</code>: array of structs representing the axes. Each struct     must have the component <code>name</code>. Further, it must     specify the binning through one of these two options: <ol> <li>regular binnings are specified through the components <code>max</code>,         <code>min</code> and <code>nbins</code> </li> <li>potentially irregular binnings are specified through the         component <code>edges</code>, which contains an array of length \\(n+1\\),         where the first and last entries denote the minimum and and         maximum of the variable, and all entries between denote the         intermediate bin boundaries. </li> </ol> </li> <li><code>uncertainty</code>: (optional) struct representing the     uncertainty of the contents. It consists of up to three components: <ul> <li><code>type</code>: denoting the kind of uncertainty, for now only Gaussian         distributed uncertainties denoted as <code>gaussian_uncertainty</code> are         supported </li> <li><code>sigma</code>: array of the standard deviation of the entries in         <code>contents</code>. Needs to be of the same length as <code>contents</code> </li> <li><code>correlation</code>: (optional) array of arrays denoting         the correlation between the contents in matrix format. Must be         of dimension length of <code>contents</code> \\(\\times\\) length of <code>contents</code>.         It can also be set to 0 to indicate no correlation. </li> </ul> </li> </ul> Example: Binned Data<pre><code>\"data\":[ \n    { \n        \"name\":\"data2\", \n        \"type\":\"binned\", \n        \"contents\":[ 9.0, 18.4 ], \n        \"axes\":[ { \"name\":\"variable1\", \"nbins\":2, \"min\":1, \"max\":3 } ] \n    }, \n    { \n        \"name\":\"asimov_data2\",\n        \"type\":\"binned\", \n        \"contents\":[ 9.0, 18.4, 13, 0. ], \n        \"axes\":[ { \"name\":\"variable1\", \"nbins\":2, \"min\":1, \"max\":3 }, { \"name\":\"variable2\", \"edges\"[0,10,100] } ] \n    }, \n    ... \n    ]\n</code></pre> <p>This type can also be used to store pre-processed data utilizing the <code>uncertainty</code> component </p> Example: Pre-processed binned Data<pre><code>\"data\":[ \n    { \n        \"name\":\"data4\", \n        \"type\":\"binned\", \n        \"contents\":[ 9.0, 18.4 ], \n        \"uncertainty\" : { \n            \"type\": \"gaussian_uncertainty\", \n            \"correlation\" : 0, \n            \"sigma\" : [ 3, 4 ]\n        }, \n        \"axes\":[ \n            { \"name\":\"variable1\", \"nbins\":2, \"min\":1, \"max\":3 }, \n            ... \n        ] \n    }, \n    ... \n    ] \n</code></pre>"},{"location":"main/#sec:likelihoods","title":"Likelihoods","text":"<p>The top-level component <code>likelihoods</code> contains an array of likelihoods in struct format specifying mappings of distributions and observations. The corresponding distributions and observations are inserted as keys in string format referencing to distributions and observations defined in the respective top-level components, or as numbers for fixed data values.  The combination of parameterized distributions \\(m_i(\\theta_i)\\) with observations \\(x_i\\) generates a likelihood function </p> \\[ \\begin{aligned} \\ensuremath{\\mathscr{L}}(\\theta_1, \\theta_2, \\ldots) &amp;=  \\prod_i \\text{PDF}(m_i(\\theta_i), x_i) \\end{aligned}  \\] <p>The components of a likelihood struct are: </p> <ul> <li><code>name</code>: custom string </li> <li><code>distributions</code>: array of strings referencing the considered     distributions </li> <li><code>data</code>: array of strings referencing the used data, must be of the     same length as the array of <code>distributions</code>. Alternatively, the     data-values for single-dimensional distributions can be given     in-line. For example, this can be used for constraint terms     representing auxiliary measurements. </li> <li><code>aux_distributions</code>: (optional) array of strings     referencing the considered auxiliary distributions defined in the     top-level component <code>distributions</code>. They can be used to encode     regularizers or penalty terms to aid the minimization. These     observed data for these distributions is implicit and not part of     <code>data</code>. </li> </ul> Example: Likelihoods<pre><code>\"likelihoods\":[ \n    { \n        \"name\":\"likelihood1\", \n        \"distributions\":[ \"dist1\", \"dist2\", \"single_dimensional_dist_1\", ... ], \n        \"data\":         [ \"data1\", \"data2\",                           0, ... ], \n        \"aux_distributions\" : [ \"regularization_term\" ] }, \n        ... \n    ] \n</code></pre>"},{"location":"main/#sec:domains","title":"Domains","text":"<p>The top-level component <code>domains</code> contains an array of domains giving information on the ranges of parameters and variables in struct format. Within a specified domain, the corresponding model is expected to yield valid values. Each domain must contain a <code>name</code> and a <code>type</code> although right now only the <code>product_domain</code> type is supported, even though others like e. g.\u00a0a simplex domain might be added later. A domain consists of the following components: </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>product_domain</code> </li> <li><code>axes</code>: array of parameters and variables in this domain (see below)  The component <code>axes</code> itself is an array of ranges each containing the components <code>min</code>, <code>max</code> and <code>name</code>. </li> <li><code>name</code>: custom string </li> <li><code>max</code>: upper bound of range </li> <li><code>min</code>: lower bound of range </li> </ul> Example: Domains<pre><code>\"domains\":[ \n    { \n        \"name\":\"domain1\", \n        \"type\":\"product_domain\", \n        \"axes\": [ \n            { \"name\" : \"par_1\", \"max\" : 1, \"min\" : 8 }, \n            { \"name\" : \"par_2\", \"max\" : 4.78, \"min\" : 6 }, \n            ... \n            ] \n    }, \n    ... \n]\n</code></pre>"},{"location":"main/#sec:parameterpoints","title":"Parameter points","text":"<p>The top-level component <code>parameter_points</code> contains an array of parameter configurations. These can be starting values for minimizations, parameter settings used to generate toy data, best-fit-values obtained, or points in parameter space used for different purposes. </p> <ul> <li><code>name</code>: custom string </li> <li><code>parameters</code>: array of parameter structs (see below)  The component <code>parameters</code> is an array of components each containing: </li> <li><code>name</code>: custom string </li> <li><code>value</code>: number, value of variable </li> <li><code>const</code>: (optional) boolean, whether variable is     constant or not. Default is <code>false</code>. </li> </ul> Example: Parameter points<pre><code>\"parameter_points\":[ \n    { \n        \"name\" : \"starting_values\", \n        \"parameters\": [ \n            { \"name\" : \"par_1\", \"value\": 3 }, \n            { \"name\" : \"par_2\", \"value\": 7, \"const\": true }, \n            ... \n            ] \n    }, \n    ... \n] \n</code></pre>"},{"location":"main/#sec:analyses","title":"Analyses","text":"<p>The top-level component <code>analyses</code> contains an array of possible (automated) analyses. To that extent, likelihoods, parameters of interest and the affiliated domains are listed. Description of the components: </p> <ul> <li><code>name</code>: long custom string </li> <li><code>likelihood</code>: name as reference to a likelihood defined in the top-level component <code>likelihoods</code> </li> <li><code>parameter_of_interest</code>: (optional) array of names as reference to parameters that are interesting for the analysis at hand </li> <li><code>domain</code>: name of a domain to be used for the parameters, defined in the top-level component <code>domains</code> </li> <li><code>init</code>: (optional) name of an initial value to be used, defined in the top-level component <code>parameter_points</code> </li> <li><code>prior</code>: (optional) name of a prior distribution, defined in the top-level component <code>distributions</code>. This is only used for Bayesian interpretations and should not be confused with auxiliary distributions listed in the likelihood section. The prior could, for example, be a product distribution of all the individual priors. If for any parameter, both a prior and a parameter domain are given, the prior should be truncated to the given parameter domain. Otherwise, implicit flat priors over the given parameter domain are assumed. </li> </ul> <p>All parameters of all distributions in the likelihood must either be listed under the domain referenced, or set to <code>const</code> in the parameter point referenced. </p> Example: Analyses<pre><code>\"analyses\": [ \n    { \n        \"name\" : \"analysis1\", \n        \"likelihood\" : \"likelihood1\", \n        \"aux_likelihood_terms\" : [\"distribtion_1\", \"distribution_2\", ...] \n        \"parameters_of_interest\" : [\"param1\"], \n        \"domain\" : \"domain1\" , \n        \"init\" : \"starting_values\", \n        \"prior\" : \"prior_dist\" \n    }, \n    ... \n]\n</code></pre>"},{"location":"main/#sec:metadata","title":"Metadata","text":"<p>The top-level component <code>metadata</code> contains meta-information related to the creation of the file. The component <code>hs3_version</code> stores the HS\\(^3\\) version and is required for now. Overview of the components: </p> <ul> <li><code>hs3_version</code>: (required) HS\\(^3\\) version number as     String for reference </li> <li><code>packages</code>: (optional) array of structs defining     packages and their version number used in the creation of this file,     depicted with the components <code>name</code> and <code>version</code> respectively </li> <li><code>authors</code>: (optional) array of authors, either     individual persons, or collaborations </li> <li><code>publications</code>: (optional) array of document     identifiers of publications associated with this file </li> <li><code>description</code>: (optional) short abstract/description     for this file </li> </ul> Example: Metadata<pre><code>\"metadata\" : { \n    \"hs3_version\" : \"0.2.0\", \n    \"packages\" : [ { \"name\": \"ROOT\", \"version\": \"6.28.02\" } ], \n    \"authors\": [\"The ATLAS Collaboration\", \"The CMS Collaboration\"], \n    \"publications\": [\"doiABCDEFG\"]\n} \n</code></pre>"},{"location":"main/#sec:misc","title":"Miscellaneous","text":"<p>The top-level component <code>misc</code> can contain arbitrary, user-created information in struct format. </p> Example: Miscellaneous<pre><code>\"misc\" : { \n    \"customkey1\" : \"custom information 1\" , \n    \"myPackage_internal\" : { \n        \"somekey\" : \"custom info only affecting myPackage\", \n        \"default_color_for_all_curves\" : \"fuchsia\" } \n    } \n</code></pre> <p>This top-level component is intended to store any and all additional information, including user- or backend-specific meta-information. Examples include, but are not limited to:  -   colors and styles for drawing distributions in this file  -   suggested settings for samplers or minimizers when working with the     distributions in this file  -   comments explaining design choices made when building the model in     this file  -   suggested names and paths for output files to be used by backends     working with this file </p>"},{"location":"main/#supplementary-material","title":"Supplementary Material","text":"<p>This section contains supplementary material referenced in section  [sec:toplevel] </p>"},{"location":"main/#sec:generic_expression","title":"Generic Expressions","text":"<p>This section details the HS<sup>3</sup> generic expression language.  Expressions can be use to specify generic functions and generic distributions.  The implementations that support generic expression must support: </p> <ul> <li>Literal integer (format <code>1234</code>), boolean (format <code>TRUE</code> and <code>FALSE</code>)     and floating point (format <code>123.4</code>, <code>1.234e2</code> and <code>1.234E2</code>) values. </li> <li>Literal values for \\(\\pi\\) (<code>PI</code>) and Euler's number (<code>EULER</code>). </li> <li>The arithmetic operators addition (<code>x + y</code>), subtraction (<code>x - y</code>),     multiplication (<code>x * y</code>), division (<code>x / y</code>) and exponentiation     (<code>x^y</code>). </li> <li>The comparison operators approximately-equal (<code>x == y</code>),     exactly-equal (<code>x === y</code>), not-approximately-equal (<code>x != y</code>),     not-exactly-equal (<code>x !== y</code>), less-than (<code>x &lt; y</code>), less-or-equal     (<code>x &lt;= y</code>), greater-than (<code>x &gt;= y</code>) and greater-or-equal (<code>x &gt;= y</code>). </li> <li>The logical operators logical-inverse (<code>!a</code>), logical-and     (<code>a &amp;&amp; b</code>), logical-or (<code>a || b</code>), less-or-equal (<code>a &lt;= b</code>),     greater-than (<code>a &gt;= b</code>) and greater-or-equal (<code>a &gt;= b</code>). </li> <li>Round brackets to specify the order of operations. </li> <li>The ternary operator <code>condition ? result_if_true : result_if_false</code> </li> <li>The functions <ul> <li><code>exp(x)</code>: Euler's number raised to the power of <code>x</code> </li> <li><code>log(x)</code>: Natural logarithm of <code>x</code> </li> <li><code>sqrt(x)</code>: The square root of <code>x</code> </li> <li><code>abs(x)</code>: The absolute value of <code>x</code> </li> <li><code>pow(x, y)</code>: <code>x</code> raised to the power of <code>y</code> </li> <li><code>pow(x, y)</code>: <code>x</code> raised to the power of <code>y</code> </li> <li><code>min(x, y)</code>: minimum of <code>x</code> and <code>y</code> </li> <li><code>max(x, y)</code>: maximum of <code>x</code> and <code>y</code> </li> <li><code>sin(x)</code>: The sine of <code>x</code> </li> <li><code>cos(x)</code>: The cosine of <code>x</code> </li> <li><code>tan(x)</code>: The tangent of <code>x</code> </li> <li><code>asin(x)</code>: The inverse sin of <code>x</code> </li> <li><code>acos(x)</code>: The inverse cosine of <code>x</code> </li> <li><code>atan(x)</code>: The inverse tangent of <code>x</code> </li> </ul> </li> </ul> <p>Symbols not defined here refer to variables in the HS<sup>3</sup> model.  The operator precedence and associativity is acorrding to the common conventions.  Spaces between operators and operands are optional. There must be no space between a function name and the function arguments, spaces between function arguments are optional (<code>f(a, b)</code> and <code>f(a,b)</code> are correct but <code>f (a, b)</code> is not allowed). </p> <p>Division must be treated as floating-point division (i.e. <code>2/3</code> should be equivalent to <code>2.0/3.0</code>). </p> <p>The approximately-equal (<code>a == b</code>) and the not-approximately-equal operator (<code>a != b</code>), should compare floating-point numbers to within a small multiple of the unit of least precision.  The behavior of any functions and operators not listed above is not defined, they are reserved for future versions of this standard. Implementations may support additional functions and operators as experimental features, but their use is considered non-standard and results in non-portable and potentially non-forward-compatible HS<sup>3</sup> documents. </p>"},{"location":"main/#references","title":"References","text":"<ol> <li> <p>The variation consists of summarizing all contributions in the     stack to a single contribution as far as treatment of the     statistical uncertainties is concerned.\u00a0\u21a9</p> </li> <li> <p>Creative Commons. Cc0 license. URL: https://creativecommons.org/publicdomain/zero/1.0.\u00a0\u21a9</p> </li> <li> <p>Kyle Cranmer, Sabine Kraml, Harrison Prosper, Philip Bechtle, Florian Bernlochner, Itay M. Bloch, Enzo Canonero, Marcin Chrzaszcz, Andrea Coccaro, Jan Conrad, Glen Cowan, Matthew Feickert, Nahuel Ferreiro, Andrew Fowlie, Lukas A. Heinrich, Alexander Held, Thomas Kuhr, Anders Kvellestad, Maeve Madigan, Farvah Nazila Mahmoudi, Knut Dundas Mor\u00e5, Mark S. Neubauer, Maurizio Pierini, Juan Rojo, Sezen Sekmen, Luca Silvestrini, Veronica Sanz, Giordon H. Stark, Riccardo Torre, Robert Thorne, Wolfgang Waltenberger, Nicholas Wardle, and Jonas Wittbrodt. Publishing statistical models: getting the most out of particle physics experiments. SciPost Physics, January 2022. URL: http://dx.doi.org/10.21468/SciPostPhys.12.1.037, doi:10.21468/scipostphys.12.1.037.\u00a0\u21a9</p> </li> <li> <p>Lukas Heinrich, Matthew Feickert, and Giordon Stark. Pyhf. URL: https://github.com/scikit-hep/pyhf/releases/tag/v0.7.0, doi:10.5281/zenodo.1169739.\u00a0\u21a9</p> </li> <li> <p>Lukas Heinrich, Matthew Feickert, Giordon Stark, and Kyle Cranmer. Pyhf: pure-python implementation of histfactory statistical models. Journal of Open Source Software, 6(58):2823, 2021. URL: https://doi.org/10.21105/joss.02823, doi:10.21105/joss.02823.\u00a0\u21a9</p> </li> <li> <p>The ROOT Team. Root-project/root. March 2022.\u00a0\u21a9</p> </li> <li> <p>Scott O. Bradner. Key words for use in RFCs to Indicate Requirement Levels. RFC 2119, March 1997. URL: https://www.rfc-editor.org/info/rfc2119, doi:10.17487/RFC2119.\u00a0\u21a9</p> </li> <li> <p>The JSON data interchange syntax. ISO/IEC 21778, November 2017. URL: https://www.iso.org/standard/71616.html.\u00a0\u21a9</p> </li> <li> <p>Roger Barlow. Extended maximum likelihood. Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, 297(3):496\u2013506, 1990. URL: https://www.sciencedirect.com/science/article/pii/0168900290913348, doi:https://doi.org/10.1016/0168-9002(90)91334-8.\u00a0\u21a9\u21a9</p> </li> <li> <p>Glen Cowan, Kyle Cranmer, Eilam Gross, and Ofer Vitells. Asymptotic formulae for likelihood-based tests of new physics. Eur. Phys. J. C, 71:1554, 2011. [Erratum: Eur.Phys.J.C 73, 2501 (2013)]. arXiv:1007.1727, doi:10.1140/epjc/s10052-011-1554-0.\u00a0\u21a9</p> </li> <li> <p>Kyle Cranmer, George Lewis, Lorenzo Moneta, Akira Shibata, and Wouter Verkerke. HistFactory: A tool for creating statistical models for use with RooFit and RooStats. Technical Report, New York U., New York, January 2012. URL: https://cds.cern.ch/record/1456844.\u00a0\u21a9</p> </li> <li> <p>ATLAS Collaboration. Measurement of inclusive and differential cross sections in the $H \\rightarrow ZZ^* \\rightarrow 4\\ell $ decay channel in \\(pp\\) collisions at \\(\\\\sqrt s=13\\) TeV with the ATLAS detector. JHEP, 10:132, 2017. arXiv:1708.02810, doi:10.1007/JHEP10(2017)132.\u00a0\u21a9</p> </li> <li> <p>Roger Barlow and Christine Beeston. Fitting using finite monte carlo samples. Computer Physics Communications, 77(2):219\u2013228, 1993. URL: https://www.sciencedirect.com/science/article/pii/001046559390005W, doi:https://doi.org/10.1016/0010-4655(93)90005-W.\u00a0\u21a9</p> </li> <li> <p>R. L. Workman and Others. Review of Particle Physics. PTEP, 2022:083C01, 2022. doi:10.1093/ptep/ptac097.\u00a0\u21a9</p> </li> </ol>"},{"location":"chapters/1_introduction/","title":"Introduction","text":"<p>This section is non-normative. </p> <p>It is widely agreed upon that the publication of likelihood models from high energy physics experiments is imperative for the preservation and public access to these results. Detailed arguments have been made elsewhere already [^Cranmer_2022]. This document sets out to provide a standardized format to publish and archive statistical models of any size and across a wide range of mathematical formalisms in a way that is readable by both humans and machines.  With the introduction of <code>pyhf</code> [^pyhf][^pyhf-joss], a <code>JSON</code> format for likelihood serialization has been put forward. However, an interoperable format that encompasses likelihoods with a scope beyond stacks of binned histograms was lacking. With the release of <code>ROOT</code> 6.26/00 [^root] and the experimental <code>RooJSONFactoryWSTool</code> therein, this gap has now been filled.  This document sets out to document the syntax and features of the Statistics Serialization Standard (HS<sup>3</sup>) for likelihoods and statistical models in general, as to be adopted by any HS<sup>3</sup>-compatible statistics framework. The examples in this document employ the <code>JSON</code> notation, but are intended to encompass also representations as <code>YAML</code> or <code>TOML</code>. </p>"},{"location":"chapters/1_introduction/#how-to-use-this-document","title":"How to use this document","text":"<p>Developers of statistical toolkits are invited to specifically refer to versions of this document relating to the support of this standard in their respective implementations.  Please note that this document as well as the HS<sup>3</sup> standard are still in development and can still undergo minor and major changes in the future. This document describes the syntax of HS<sup>3</sup> v0.2.9. </p>"},{"location":"chapters/1_introduction/#sec:hs3-semantics","title":"Statistical semantics of HS<sup>3</sup>","text":""},{"location":"chapters/1_introduction/#sec:models-and-parameters","title":"Statistical models, probability distributions and parameters","text":"<p>HS<sup>3</sup> takes a \"forward-modelling\" approach throughout: a statistical model \\(m\\) maps a space \\(\\Theta\\) of free parameters \\(\\theta\\) to a space of probability distributions that describe the possible outcomes of a specific experiment. For any given parameters \\(\\theta\\), the model returns a concrete probability distribution \\(m(\\theta)\\). Observed data \\(x\\) is then treated as random variate, presumed to be drawn from the model: \\(x \\sim m(\\theta)\\).  Parameters in HS<sup>3</sup> are always named, so semantically the elements of a parameter space \\(\\Theta\\) are named tuples \\(\\theta\\) (meaning tuples in which every entry has a name). Even if there is only a single free parameter, \\(\\theta\\) should be thought of as a single-entry named tuple. In the current version of this standard, parameter tuples must be flat and only consist of real numbers, vector-valued or nested entries are not supported yet. Future versions of the standard will likely be less restrictive, especially with respect to discrete or vector-valued parameters. Parameter domains defined as part of this standard may be of various types, even though the current version only supports product domains. Future versions are likely to be less restrictive in this regard.  Mathematically and computationally, it is often convenient to treat parameters as flat real-valued vectors instead of named tuples, it is the responsibility of the implementation to map between these different views of parameters when and where necessary.  Probability distributions in HS<sup>3</sup> (see  Distributions) are typically parameterized. Any instance of a distribution that has some of its parameters bound to names instead of concrete values, e.g. \\(m = d_{\\mu = a, \\sigma = 0.7, \\lambda = b, ...}\\), constitutes a valid statistical model \\(m(\\theta)\\) with model parameters \\(\\theta = (a, b)\\).  When probability distributions are combined via a Cartesian product (see  Product distribution), then the named tuples that contain their free parameter values are concatenated. So \\(m = d_{\\mu = a, \\sigma = b} \\times d_{\\mu = c, \\sigma = 0.7}\\) constitutes a model \\(m(\\theta)\\) with model parameters \\(\\theta = (a, b, c)\\).  Distribution parameters may also be bound to the output of functions, and if those functions have inputs that are bound to names instead of values (or again bound to such functions, recursively), then those names become part of the model parameters. A configuration \\(m = d_{\\mu = a, \\sigma = 0.7, \\lambda = f}, f = \\texttt{sum}(4.2, g), g = \\texttt{sum}(1.3, b)\\), for example, also constitutes a (different) model \\(m(\\theta)\\) with parameters \\(\\theta = (a, b, c)\\).  If all parameter values of a probability distribution are set to concrete values, so if there are not directly (or indirectly via functions) bound to names, we call this probability distribution a concrete distribution here. Such distributions can be used as Bayesian  priors (see Bayesian inference).  The variates of all distributions (so the possible results of random draws from them) are also named tuples in all cases. So even instances of univariate distributions, like the normal distributions, have variates like \\((x = \\ldots)\\). The names in the variate tuples can be configured for each instance of a distribution, and must be unique across all distributions that are used together in a model. In Cartesian products of distributions, their variate tuples are concatenated. As with parameter tuples, nested tuples are not supported. The tuple entries, however, may be vector-valued, in contrast to parameter tuples. </p>"},{"location":"chapters/1_introduction/#sec:what-is-a-pdf","title":"Probability density functions (PDFs)","text":"<p>Statistics literature often discriminates between probability density functions (PDF) for continuous probability distributions and probability mass functions (PMF) for discrete probability distributions. This standard use the term PDF for both continuous and discrete distributions. The concept of density is to be understood in terms of densities in the realm of measure theory here, that is the density of a probability measure (distribution) is its Radon-Nikodym derivative in respect to an (implied) reference measure.  The choice of reference measure would be arbitrary in principle, which scales likelihood functions  (Sec. Likelihood) by a constant factor that depends on choice of reference. In this standard, a specific reference measures is implied for each probability distribution, typically the Lebesgue measure for continuous distributions and the counting measure for discrete distributions. The standard aims to to match the PDF (resp.\u00a0PMF) most commonly used in literature for each specific probability distribution and the mathematical form of the PDF is documented explicitly for each distribution in the standard. So within HS<sup>3</sup>, probability densities and likelihood functions are unambiguous.  Here we use \\(\\text{PDF}(m(\\theta), x)\\) to denote the density value of the probability distribution/measure \\(m\\), parameterized by \\(\\theta\\), at the point/variate \\(x\\), in respect to the implied reference for \\(m\\). </p>"},{"location":"chapters/1_introduction/#sec:data-generation","title":"Observed and simulated data","text":"<p>The term data refers here to any collection of values that represents the outcome of an experiment. Data takes the same form as variates of distributions (see  Distributions, i. e.\u00a0named tuple of real values or vectors. To compare given data with a given model, the names and shapes of the data entries must match the variates of the probability distributions \\(m(\\theta)\\) that the model returns for a specific choice of parameters \\(\\theta\\).  This means that given a model \\(m\\) and concrete parameter values \\(\\theta\\), drawing a set of random values from the probability distribution \\(m(\\theta)\\) produces a valid set of simulated observations. Implementations can use this to provide mock-data generation capabilities. </p>"},{"location":"chapters/1_introduction/#sec:likelihood-definition","title":"Likelihood functions","text":"<p>The concrete probability distribution \\(m(\\theta)\\) that a model \\(m\\) returns for specific parameter values \\(\\theta\\) can be compared to observed data \\(x\\). This gives rise to a likelihood \\(\\mathcal{L}_{m,x}(\\theta) = \\text{PDF}(m(\\theta), x)\\) that is a real-valued function on the parameter space. Multiple distributions/models that describe different modes of observation can be combined with multiple sets of data that cover those modes of observation into a single likelihood (Sec.  [sec:likelihoods]). In addition to using observed data, implementations may provide the option to use random data generated from  the model (see 1.2.3) to check for Monte-Carlo closure. </p>"},{"location":"chapters/1_introduction/#sec:frequentist-inference","title":"Frequentist parameter inference","text":"<p>The standard method of frequentist inference is the maximum (or, respectively, profile) likelihood method. In the vast majority of cases, the test statistic used here is the likelihood ratio, that is, the ratio of two values of the likelihood corresponding to two different points in parameter space: one that maximizes the likelihood unconditionally, one one that maximizes the likelihood under some condition such as the values of the parameters of interest expected in the absence of a deviation from the null hypothesis. The corresponding building blocks for such an analysis, such as the list of parameters of interest and the likelihood function to be used, are specified in the analysis section of an HS<sup>3</sup> configuration (Sec. Analyses). </p>"},{"location":"chapters/1_introduction/#sec:bayesian-inference","title":"Bayesian parameter inference","text":"<p>The standard also encompasses the specification of Baysian posterior distributions over parameters by combining (Sec.  Analyses) likelihoods with probabilty distributions that acts the priors. Here concrete distributions are used to describe the prior probability of parameters in addition to parameterized distributions that are used to describe of the probability of observing specific data. </p>"},{"location":"chapters/1_introduction/#how-to-read-this-document","title":"How to read this document","text":"<p>In the context of this document, any <code>JSON</code> object is referred to as a struct. A key-value-pair inside such a struct is referred to as a component. If not explicitly stated otherwise, all components mentioned are mandatory.  The components located inside the top-level struct are referred to as top-level components.  The keywords optional and required, as well as should and may are used in accordance with IETF requirement levels [^rfc2119]. </p>"},{"location":"chapters/1_introduction/#terms-and-types","title":"Terms and Types","text":"<p>This is a list of used types and terms in this document. </p> <ul> <li><code>struct</code>: represented with { }, containing a key:value mapping,     keys are of type <code>string</code>. </li> <li><code>component</code>: key-value pair within a struct </li> <li><code>array</code> array of items (either <code>string</code>s or <code>number</code>s) without keys. Represented with <code>[...]</code>. </li> <li><code>string</code>: references to objects, names and arbitrary information.     Represented with </li> <li><code>number</code>: either floating or integer type values </li> <li><code>boolean</code>: boolean values; they can be encoded as <code>true</code> and <code>false</code> </li> </ul> <p>All <code>struct</code>s defining functions, distributions, parameters, variables, domains, likelihoods, data or parameter points will be referred to as <code>object</code>s. All <code>object</code>s must always have a component <code>name</code> that must be unique among all <code>object</code>s. </p> <p>Within most top-level <code>component</code>s, any one <code>string</code> given as a value to any component should refer to the <code>name</code> of another <code>object</code>, unless explicitly stated otherwise. Top-level <code>component</code>s in which this is not the case are explicitly marked as such. </p>"},{"location":"chapters/1_introduction/#file-format","title":"File format","text":"<p>HS3 documents are encoded in the JSON format as defined in ISO/IEC 21778:2017 [^json]. Implementations may support other serialization formats that support a non-ambiguous mapping to JSON, such as TOML or YAML, in which case they should use a different file extension. </p>"},{"location":"chapters/1_introduction/#validators","title":"Validators","text":"<p>Future versions of this standard will recommend official validator implementations and schemata. Currently, these have not been finalized. </p>"},{"location":"chapters/1_introduction/#how-to-get-in-touch","title":"How to get in touch","text":"<p>Visit the GitHub page https://github.com/hep-statistics-serialization-standard/hep-statistics-serialization-standard </p>"},{"location":"chapters/2.1.1_fundamental_distributions/","title":"Fundamental Distributions","text":""},{"location":"chapters/2.1.1_fundamental_distributions/#univariate-fundamental-distributions","title":"Univariate fundamental distributions","text":"<p>This section contains univariate fundamental distributions in the sense that they cannot refer to any other distribution -- only to functions, parameters and exactly one variable.  The of the Argus background distribution is defined as </p>"},{"location":"chapters/2.1.1_fundamental_distributions/#argus-distribution","title":"Argus distribution","text":"\\[ \\begin{aligned} \\text{ArgusPdf}(m, m_0, c, p) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\cdot m \\cdot \\left[ 1 - \\left( \\frac{m}{m_0} \\right)^2 \\right]^p \\cdot \\exp\\left[ c \\cdot \\left(1 - \\left(\\frac{m}{m_0}\\right)^2 \\right) \\right] \\end{aligned}  \\] <p>and describes the ARGUS background shape. </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>argus_dist</code> </li> <li><code>mass</code>: name of the variable \\(m\\) used as mass </li> <li><code>resonance</code>: value or name of the parameter used as resonance \\(m_0\\) </li> <li><code>slope</code>: value or name of the parameter used as slope \\(c\\) </li> <li><code>power</code>: value or name of the parameter used as exponent \\(p\\). </li> </ul> <p>The of a continued Poisson distribution of the variable \\(x\\) is defined as </p>"},{"location":"chapters/2.1.1_fundamental_distributions/#continued-poisson-distribution","title":"Continued Poisson distribution","text":"\\[ \\begin{aligned} \\text{ContinuedPoissonPdf}(x, \\lambda) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\exp\\left(x \\cdot \\ln \\lambda - \\lambda - \\ln \\Gamma(x+1)\\right), \\end{aligned}  \\] <p>where \\(\\Gamma\\) denotes the Euler Gamma function.  This function is similar the the Poisson distribution (see  Poisson distribution), but can accept non-integer values for \\(x\\). Notably, the differences between the two might be significant for small values of \\(x\\) (below x). Nevertheless, the distribution is useful to deal with datasets with non-integer event counts, such as asimov datasets [^asymptotics]. </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>poisson_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) (usually referred to as \\(k\\) for the     standard integer case) </li> <li><code>mean</code>: value or name of the parameter used as mean \\(\\lambda\\).  The of a continuous uniform distribution is defined as: </li> </ul>"},{"location":"chapters/2.1.1_fundamental_distributions/#uniform-distribution","title":"Uniform distribution","text":"\\[ \\begin{aligned} \\text{UniformPdf}(x) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>uniform_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\)  The generalized Asymmetrical Double-Sided Crystall Ball line shape, composed of a Gaussian distribution at the core, connected with two powerlaw distributions describing the lower and upper tails, given by </li> </ul>"},{"location":"chapters/2.1.1_fundamental_distributions/#crystalball-distribution","title":"CrystalBall distribution","text":"\\[ \\begin{aligned} \\text{CrystalBallPdf}(m;m_0,\\sigma,\\alpha_L,n_L,\\alpha_R,n_R) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\begin{cases} A_L \\cdot (B_L - \\frac{m - m_0}{\\sigma_L})^{-n_L}, &amp; \\mbox{for }\\frac{m - m_0}{\\sigma_L} &lt; -\\alpha_L \\\\ \\exp \\left( - \\frac{1}{2} \\cdot \\left[ \\frac{m - m_0}{\\sigma_L} \\right]^2 \\right), &amp; \\mbox{for }\\frac{m - m_0}{\\sigma_L} \\leq 0 \\\\ \\exp \\left( - \\frac{1}{2} \\cdot \\left[ \\frac{m - m_0}{\\sigma_R} \\right]^2 \\right), &amp; \\mbox{for }\\frac{m - m_0}{\\sigma_R} \\leq \\alpha_R \\\\ A_R \\cdot (B_R + \\frac{m - m_0}{\\sigma_R})^{-n_R}, &amp; \\mbox{otherwise}, \\\\ \\end{cases} \\end{aligned}  \\] <p>where </p> \\[ \\begin{aligned} A_i &amp;= \\left(\\frac{n_i}{\\left| \\alpha_i \\right|}\\right)^{n_i} \\cdot \\exp\\left(- \\frac {\\left| \\alpha_i \\right|^2}{2}\\right) \\\\ B_i &amp;= \\frac{n_i}{\\left| \\alpha_i \\right|}  - \\left| \\alpha_i \\right| \\\\ \\end{aligned}  \\] <p>The keys are </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>crystalball_dist</code> </li> <li><code>m</code>: name of the variable \\(m\\) </li> <li><code>m0</code>: name or value of the central value \\(m_0\\) </li> <li><code>alpha</code>: value or names of \\(\\alpha_L\\) and \\(\\alpha_R\\) from above.     must not be used in conjuction with <code>alpha_L</code> or     <code>alpha_R</code>. </li> <li><code>alpha_L</code>: value or names of \\(\\alpha_L\\) from above. must     not be used in conjuction with <code>alpha</code>. </li> <li><code>alpha_R</code>: value or names of \\(\\alpha_R\\) from above. must     not be used in conjuction with <code>alpha</code>. </li> <li><code>n</code>: value or names of \\(n_L\\) and \\(n_R\\) from above. must     not be used in conjuction with <code>n_L</code> or <code>n_R</code>. </li> <li><code>n_L</code>: value or names of \\(n_L\\) from above. must not be     used in conjuction with <code>n</code>. </li> <li><code>n_R</code>: value or names of \\(n_R\\) from above. must not be     used in conjuction with <code>n</code>. </li> <li><code>sigma</code>: value or names of \\(\\sigma_L\\) and \\(\\sigma_R\\) from above.     must not be used in conjuction with <code>sigma_L</code> or     <code>sigma_R</code>. </li> <li><code>sigma_L</code>: value or names of \\(\\sigma_L\\) from above. must     not be used in conjuction with <code>sigma</code>. </li> <li><code>sigma_R</code>: value or names of \\(\\sigma_R\\) from above. must     not be used in conjuction with <code>sigma</code>. </li> </ul>"},{"location":"chapters/2.1.1_fundamental_distributions/#exponential-distribution","title":"Exponential distribution","text":"\\[ \\begin{aligned} \\text{ExponentialPdf}(x, c) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\cdot \\exp(-c\\cdot x) \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>exponential_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>c</code>: value or name of the parameter used as coefficient \\(c\\).  The of a Gaussian/Normal distribution is defined as </li> </ul>"},{"location":"chapters/2.1.1_fundamental_distributions/#gaussian-normal-distribution","title":"Gaussian Normal distribution","text":"\\[ \\begin{aligned} \\text{GaussianPdf}(x, \\mu, \\sigma) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\exp\\left(\\frac{(x-\\mu)^2}{\\sigma^2}\\right) \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>gaussian_dist</code> or <code>normal_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>mean</code>: value or name of the parameter used as mean value \\(\\mu\\) </li> <li><code>sigma</code>: value or name of the parameter encoding the standard     deviation \\(\\sigma\\).  The of the log-normal distribution is defined as </li> </ul>"},{"location":"chapters/2.1.1_fundamental_distributions/#log-normal-distribution","title":"Log-Normal distribution","text":"\\[ \\begin{aligned} \\text{LogNormalPdf}(x, \\mu, \\sigma) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}} \\frac{1}{ x } \\exp\\left( -\\frac{(\\ln(x)-\\mu)^2}{2\\sigma^2}\\right) \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>lognormal_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>mu</code>: value or name of the parameter used as \\(\\mu\\) </li> <li><code>sigma</code>: value or name of the parameter \\(\\sigma\\) describing the     shape </li> </ul>"},{"location":"chapters/2.1.1_fundamental_distributions/#dist:poisson","title":"Poisson distribution","text":"<p>The Poisson distribution of the variable \\(x\\) is defined as </p> \\[ \\begin{aligned} \\text{PoissonPdf}(x, \\lambda) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\frac{\\lambda^x}{x!}  \\text{e}^{-\\lambda}. \\end{aligned}  \\] <p>where \\(x\\) is required to be an integer.  In this case, the behavior for non-integer values of \\(x\\) is undefined.  -   <code>name</code>: custom unique string  -   <code>type</code>: <code>poisson_dist</code>  -   <code>x</code>: name of the variable \\(x\\) (usually referred to as \\(k\\) for the     standard integer case)  -   <code>mean</code>: value or name of the parameter used as mean \\(\\lambda\\).  The of a polynomial distribution is defined as </p>"},{"location":"chapters/2.1.1_fundamental_distributions/#polynomial-distribution","title":"Polynomial distribution","text":"\\[ \\begin{aligned} \\text{PolynomialPdf}(x, a_0, a_1, a_2, ...) = \\frac{1}{\\ensuremath{\\mathcal{M}}} \\sum_{i=0}^n a_i x^i = a_0 + a_1 x + a_2 x^2 + ... \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>polynomial_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>coefficients</code>: array of coefficients \\(a_i\\). The length of this     array implies the degree of the polynomial. </li> </ul>"},{"location":"chapters/2.1.1_fundamental_distributions/#multivariate-fundamental-distributions","title":"Multivariate fundamental distributions","text":"<p>This section contains multivariate fundamental distributions. They may refer to functions, parameters and more than one variable.  This distributions represents a product of Poisson distributions defining the statistical uncertainties of the histogram templates defined in a <code>histfactory_func</code>. </p>"},{"location":"chapters/2.1.1_fundamental_distributions/#barlow-besston-lite-constraint-distribution","title":"Barlow-Besston-Lite Constraint distribution","text":"\\[ \\begin{aligned} \\text{BarlowBeestonLitePoissonConstraintPdf}(x) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}} \\prod_i^n \\text{PoissonPdf}(x_i\\cdot \\tau_i,\\tau_i) \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>barlow_beeston_lite_poisson_constraint_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>expected</code>: array of central values \\(\\tau_i\\)  The of the multivariate normal distribution is defined as </li> </ul>"},{"location":"chapters/2.1.1_fundamental_distributions/#multivariate-normal-distribution","title":"Multivariate normal distribution","text":"\\[ \\begin{aligned} \\text{MvNormalPdf}(\\mathbf{x}, \\boldsymbol\\mu, \\boldsymbol\\Sigma) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}} \\exp \\left( -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol\\mu)^{\\!\\mathsf{T}} \\boldsymbol\\Sigma^{-1}(\\mathbf{x} - \\boldsymbol\\mu) \\right), \\end{aligned}  \\] <p>with \\(\\boldsymbol\\Sigma \\in \\mathbb{R}^{k\\times k}\\) being positive-definite. </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>multivariate_normal_dist</code> </li> <li><code>x</code>: array of names of the variables \\(\\mathbf{x}\\). This also     includes mixed arrays of values and names. </li> <li><code>mean</code>: array of length \\(k\\) of values or names of the parameters     used as mean values \\(\\boldsymbol\\mu\\) </li> <li><code>covariances</code>: an array comprised of \\(k\\) sub-arrays, each of which     is also of length \\(k\\), designed to store values or names of the     entries of the covariance matrix \\(\\boldsymbol\\Sigma\\). In general,     the covariance matrix \\(\\boldsymbol\\Sigma\\) must be     symmetric and positive semi-definite. </li> </ul> <p>Note: Users should prefer the specific distributions defined in this standard over generic distributions where possible, as implementations of these will typically be more optimized. Generic distributions should only be used if no equivalent specific distribution is defined. </p> <p>A generic distribution is defined by an expression that respresents the PDF of the distribution in respect to the Lebesque measure. The expression must be a valid HS<sup>3</sup>-expression string (see Section  Generic Expressions). </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>generic_dist</code> </li> <li><code>expression</code>: a string with a generic mathematical expression.     Simple mathematical syntax common to most programming languages     should be used here, such as <code>x-2*y+z</code>. The arguments <code>x</code>, <code>y</code> and     <code>z</code> in this example must be parameters, functions or     variables.  The distribution is normalized by the implementation, a normalization term should not be included in the expression. If the expression results in a negative value, the behavior is undefined. </li> </ul>"},{"location":"chapters/2.1.1_fundamental_distributions/#histfactory-distribution","title":"HistFactory distribution","text":"<p>HistFactory [^hf] is a language to describe statistical models consisting only of \"histograms\" (which is used interchangeably with \"step-functions\" in this context). Each HistFactory distribution describes one \"channel\" or \"region\" of a binned measurement, containing a stack of \"samples\", i. e.\u00a0binned distributions sharing the same binning (step-functions describing the signal or background of a measurement). Such a HistFactory model is shown in Figure 1 (originally from  [^atlashzz]). Each of the contributions may be subject to <code>modifiers</code>. </p> <p> </p> <p>The prediction for a binned region is given as </p> \\[ \\begin{aligned} \\lambda(x)=\\sum_{s\\in\\text{samples}} \\left[ \\left( d_s(x) + \\sum_{\\delta\\in M_{\\delta}} \\delta(x,\\theta_\\delta) \\right) \\prod_{\\kappa\\in M_\\kappa} \\kappa(x,\\theta_\\kappa)   \\right] \\end{aligned}  \\] <p>Here \\(d_s(x)\\) is the prediction associated with the sample \\(s\\), a step function </p> \\[ \\begin{aligned} d_s(x) = \\chi^{y_s}_{b}(x) \\end{aligned}  \\] <p>In this section, \\(\\chi^{y_s}_{b}(x)\\) denotes a generic step function in the binning \\(b\\) such that \\(\\chi_{b}(x) = y_{s,i}\\), some constant, if \\(x\\in[b_i,b_{i+1})\\). The \\(y_{s,i}\\) in this case are the bin contents (yields) of the histograms.  The \\(M_\\kappa\\) are the multiplicative modifiers, the \\(M_\\delta\\) are the additive modifiers. Each of the modifiers is either multiplicative (\\(\\kappa\\)) or additive (\\(\\delta\\)). All samples and modifiers share the same binning \\(b\\).  The modifiers depend on a set of nuisance parameters \\(\\theta\\), where each modifier can only depend on one \\(\\theta_i\\), but the \\(\\theta_i\\) can take the form of vectors and the same \\(\\theta_i\\) can be shared by several modifiers. By convention, these are denoted \\(\\alpha\\) if they affect all bins in a correlated way, and \\(\\gamma\\) if they affect only one bin at a time. The types of modifiers are </p> <ul> <li>A uncorrelated shape systematic or <code>shapefactor</code> modifier is a     multiplicative modifier that scales each single bin by the value of     some independent parameter \\(\\gamma\\). Here, \\(\\theta_i=\\vec{\\gamma}\\),     where the length of \\(\\vec{\\gamma}\\) is equal to the number of bins in     this region. This type of modifier is sometimes called <code>shapesys</code>,     with some nuance in the meaning. However, both are synonymous in the     context of this standard. </li> <li>A correlated shape systematic or <code>histosys</code> modifier is an     additive modifier that adds or subtracts a constant step function     \\(\\chi^f\\), scaled with a single factor \\(\\alpha\\). The modifier     contains a <code>data</code> section, which contains the subsections     \\(\\texttt{hi}\\) and \\(\\texttt{lo}\\) that help to define the step     function \\(\\chi^f\\). They contain <code>contents</code>, which define the     bin-wise additions or subtractions for \\(\\alpha=1\\). Here,     \\(\\theta_i=\\alpha\\). </li> <li>A normalization systematic or <code>normsys</code> modifier is a     multiplicative modifier that scales the entire sample with the same     constant factor \\(f\\) that is a function of \\(\\alpha\\). The modifier     contains a <code>data</code> section, which contains the values \\(\\texttt{hi}\\)     and \\(\\texttt{lo}\\) that help to define \\(f\\). There are different     functional forms that can be chosen for \\(f\\). However, by convention     \\(f(\\alpha=0)=1\\), \\(f(\\alpha=+1)=\\)\"<code>hi</code>\" and     \\(f(\\alpha=-1)=\\)\"<code>lo</code>\". In this case, \\(\\theta_i=\\alpha\\). </li> <li>A normalization factor or <code>normfactor</code> modifier is a     multiplicative modifier that scales the entire sample in this region     with the value of the parameter \\(\\mu\\) itself. In this case,     \\(\\theta_i=\\mu\\). </li> <li>The <code>staterror</code> modifier is a shorthand for encoding uncorrelated     statistical uncertainties on the values of the step-functions, using     a variant<sup>1</sup> of the Barlow-Beeston Method [^barlowbeeston]. Here,     the relative uncertainty on the sum of all samples in this region     containing the <code>staterror</code> modifier is computed bin-by-bin. Then, a     constrained uncorrelated shape systematic (<code>shapesys</code>) is created,     encoding these relative uncertainties in the corresponding <code>Poisson</code>     (or <code>Gaussian</code>) constraint term. </li> </ul> <p>The different modifies and their descriptions are also summarized in the following table: </p> Type of Modifier Description Definition Free Parameters Number of Free Parameters <code>histosys</code> Correlated Shape systematic \\(\\delta(x,\\alpha) = \\alpha * \\chi_b^f\\) \\(\\alpha\\) 1 <code>normsys</code> Normalization systematic \\(\\kappa(x,\\alpha) = f(\\alpha)\\) \\(\\alpha\\) 1 <code>normfactor</code> Normalization factor \\(\\kappa(x,\\mu) = \\mu\\) \\(\\mu\\) 1 <code>shapefactor</code>, <code>staterror</code> Shape factor \\(\\kappa(x,\\vec{\\gamma}) = \\chi_b^{\\gamma}\\) \\(\\gamma_0\\), ..., \\(\\gamma_n\\) #bins <p>The <code>staterror</code> modifier is a special subtype of <code>shapefactor</code>, where the mean of the constraint is given as the sum of the predictions of all the samples carrying a <code>staterror</code> modifier in this bin.  The way modifiers affect the yield in the corresponding bin is subject to an interpolation function. The <code>overallsys</code> and <code>histosys</code> modifiers thus allow for an additional key <code>interpolation</code>, which identifies one of the following functions: </p> <ul> <li><code>lin</code>: \\(\\begin{cases}     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{high}} - y_{\\textit{nominal}}) \\text{ if } x\\geq0\\\\     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{nominal}} - y_{\\textit{low}}) \\text{ if } x&lt;0     \\end{cases}\\) </li> <li><code>log</code>: \\(\\begin{cases}     y_{\\textit{nominal}} \\cdot \\left(\\frac{y_{\\textit{high}}}{y_{\\textit{nominal}}}\\right)^x \\text{ if } x\\geq0\\\\     y_{\\textit{nominal}} \\cdot \\left(\\frac{y_{\\textit{low}}}{y_{\\textit{nominal}}}\\right)^{-x}\\text{ if } x&lt;0     \\end{cases}\\) </li> <li><code>parabolic</code>: \\(\\begin{cases}     y_{\\textit{nominal}} + (2s+d)\\cdot(x-1)+(y_{\\textit{high}} - y_{\\textit{nominal}}) \\text{ if } x&gt;1\\\\     y_{\\textit{nominal}} - (2s-d)\\cdot(x+1)+(y_{\\textit{low}} - y_{\\textit{nominal})}\\text{ if } x&lt;-1\\\\     s \\cdot x^2 + d\\cdot x  \\text{ otherwise}     \\end{cases}\\)\\     with     \\(s=\\frac{1}{2}(y_{\\textit{high}} + y_{\\textit{low}}) - y_{\\textit{nominal}}\\)     and \\(d=\\frac{1}{2}(y_{\\textit{high}} - y_{\\textit{low}})\\) </li> <li><code>poly6</code>: \\(\\begin{cases}     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{high}} - y_{\\textit{nominal}}) \\text{ if } x&gt;1\\\\     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{nominal}} - y_{\\textit{low}}) \\text{ if } x&lt;-1\\\\     y_{\\textit{nominal}} + x \\cdot (S + x \\cdot A \\cdot (15 + x^2 \\cdot (3x^2-10))) \\text{ otherwise}     \\end{cases}\\)\\     with \\(S = \\frac{1}{2}(y_{\\textit{high}} - y_{\\textit{low}})\\) and     \\(A=\\frac{1}{16}(y_{\\textit{high}} + y_{\\textit{low}} - 2\\cdot y_{\\textit{nominal}})\\) </li> </ul> <p>Modifiers can be constrained. This is indicated by the component <code>constraint</code>, which identifies the type of the constraint term. In essence, the likelihood picks up a penalty term for changing the corresponding parameter too far away from its nominal value. The nominal value is, by convention, defined by the type of constraint, and is 0 for all modifiers of type <code>sys</code> (<code>histosys</code>, <code>normsys</code>) and is 1 for all modifiers of type <code>factor</code> (<code>normfactor</code>, <code>shapefactor</code>). The strength of the constraint is always such that the standard deviation of constraint distribution is \\(1\\). </p> <p>The supported constraint distributions, also called constraint types, are <code>Gauss</code> for a gaussian with unit width (a gaussian distribution with a variance of \\(1\\)), <code>Poisson</code> for a unit Poissonian (e.g. a continous Poissonian with a central value 1), or <code>LogNormal</code> for a unit LogNormal,. If a constraint is given, a corresponding distribution will be considered in addition to the <code>aux_likelihood</code> section of the likelihood, constraining the parameter to its nominal value. </p> <p>An exception to this is provided by the <code>staterror</code> modifier as described above, and the <code>shapesys</code> for which a Poissonian constraint is defined with the central values defined as the squares of the values defined in <code>vals</code>. </p> <p>The components of a HistFactory distribution are: </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>histfactory_yield</code> </li> <li><code>axes</code>: array of structs representing the axes. If given each struct     needs to have the component <code>name</code>. Further,     (optional) components are <code>max</code>, <code>min</code> and <code>nbins</code>,     or, alternatively, <code>edges</code>. The definition of the axes follows the     format for binned data (see Section      Binned Data). </li> <li><code>samples</code>: array of structs containing the samples of this channel.     For details see below.  Struct of one sample: </li> <li><code>name</code>: (optional) custom string, unique within this     function </li> <li><code>data</code>: struct containing the components <code>contents</code> and <code>errors</code>,     depicting the data contents and their errors. Both components are     arrays of the same length. </li> <li><code>modifiers</code>: array of structs with each struct containing a     component <code>type</code> of the modifier, as well as a component <code>parameter</code>     (defining a string) or a component <code>parameters</code> (defining an array     of strings) relating to the name or names of parameters controlling     this modifier. Further (optional) components are     <code>data</code> and <code>constraint</code>, both depending on the type of modifier. For     details on these components, see the description above.  Two modifiers are correlated exactly if they share the same parameters as indicated by <code>parameter</code> or <code>parameters</code>. In such a case, it is mandatory that they share the same constraint term. If this is not the case, the behavior is undefined. </li> </ul> HistFactory<pre><code>{\n  \"name\": \"myAnalysisChannel\",\n  \"type\": \"histfactory_dist\",\n  \"axes\": [ { \"max\": 1.0, \"min\": 0.0, \"name\": \"myRegion\", \"nbins\": 2 } ],\n  \"name\":\"myChannel1\",\n  \"samples\": [\n           {  \"name\": \"mySignal\",\n              \"data\": { \"contents\": [ 0.5, 0.7 ], \"errors\": [ 0.1, 0.1 ] },\n          \"modifiers\": [\n                 { \"parameter\": \"Lumi\", \"type\": \"normfactor\" },\n                 { \"parameter\": \"mu_signal_strength\", \"type\": \"normfactor\" },\n                 { \"constraint\": \"Gauss\", \"data\": { \"hi\": 1.1, \"lo\": 0.9 }, \"parameter\": \"my_normalization_systematic_1\", \"type\": \"normsys\" },\n                 { \"constraint\": \"Poisson\", \"parameters\": [\"gamma_stat_1\",\"gamma_stat_2\"], \"type\": \"staterror\" },\n                 { \"constraint\": \"Gauss\", \"data\": { \"hi\": { \"contents\": [ -2.5, -3.1 ] }, \"lo\": { \"contents\": [ 2.2, 3.7 ] } }, \"parameter\": \"my_correlated_shape_systematic_1\", \"type\": \"histosys\" },\n                 { \"constraint\": \"Poisson\", \"data\": { \"vals\": [ 0.0, 1.2 ] }, \"parameter\": \"my_uncorrelated_shape_systematic_2\", \"type\": \"shapesys\" }\n                   ]\n           },\n               { \"name\": \"myBackground\" ... }\n         ]\n} \n</code></pre>"},{"location":"chapters/2.1.1_fundamental_distributions/#relativistic-breit-wigner-distribution","title":"Relativistic Breit-Wigner distribution","text":"<p>The describes the lineshape of a resonance studies in the mass spectrum of two particle system. It is assumed that the resonance can decay into a list of channels.  The first channel in the list indicates the system for which mass distribution is modelled. </p> \\[ \\begin{aligned}  \\label{eq:relativistic_breit_wigner_dist} \\text{BreitWignerPDF}(m, m_\\text{BW}) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}}\\frac{m \\Gamma_1(m)}{\\left|m_\\text{BW}^2-m^2 - i m_\\text{BW} \\Gamma(m)\\right|^2} ,\\\\ \\nonumber \\Gamma(m) &amp;= \\sum_i \\Gamma_i(m) ,\\\\ \\nonumber \\end{aligned}  \\] <p>When modelling the mass spectrum, the term \\(m\\) in the numerator of  Eq. (Breit-Wigner) accounts for a jacobian of transformation from \\(m^2\\) to \\(m\\). The width term \\(\\Gamma_1(m)\\) adds for the phase space factor for the channel of interest </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>relativistic_breit_wigner_dist</code> </li> <li><code>mass</code>: name of the mass variable \\(m_\\text{BW}\\) </li> <li><code>channels</code>: list of <code>structs</code> encoding the channels </li> </ul> <p>Each of the channels is defined by the partial width \\(\\Gamma_i(m)\\), given as </p> \\[ \\begin{aligned} \\Gamma_i(m) &amp;= \\Gamma_{\\text{BW},i}  n_{li}^2(m)\\rho_i(m) ,\\\\ \\nonumber \\rho_i(m) &amp;= 2q_i(m)/m ,\\\\ \\nonumber q_i(m) &amp;= \\sqrt{(m^2-(m_{1i}+m_{2i})^2)(m^2-(m_{1i}-m_{2i})^2)} / (2m) ,\\\\ \\nonumber n_{li}(m) &amp;= z_i^{li}(m)   h_{li}(z_i(m)) ,\\\\ \\nonumber z_i(m) &amp;= q_i(m)R_i  \\end{aligned}  \\] <p>The \\(h_l(z)\\) is the standard Blatt-Weisskopf form-factors, \\(h_0^2(z) = 1/(1+z^2)\\), \\(h_1^2(z) = 1/(9+3z^2+z^4)\\), and so on (Eqs.(50.30-50.35) in Ref.\u00a0[^pdg2023]).\\ The <code>struct</code>s defining the channels should contain the following keys: </p> <ul> <li><code>name</code>: name of the final state (optional) </li> <li><code>Gamma</code>: partial width \\(\\Gamma_{\\text{BW}}\\) of the resonance </li> <li><code>m1</code>: mass \\(m_1\\) of the first particle the resonance decays into     (default value \\(0\\)) </li> <li><code>m2</code>: mass \\(m_2\\) of the second particle the resonance decays into     (default value \\(0\\)) </li> <li><code>l</code>: orbital angular momentum \\(l\\) (default value \\(0\\)) </li> <li><code>R</code>: form-factor size parameter \\(R\\) (default value \\(3\\) GeV)  For non-zero angular momentum, \\(\\Gamma_i(m_\\text{BW})\\) gives an approximation to the partial width of the resonance, not \\(\\Gamma_{\\text{BW},i}\\).  A commonly used approximation of the relativistic Breit-Wigner function with the constant width is a special case of the  Eq. (Breit-Wigner), where the <code>[channels]</code> argument contains a single channel with \\(m_1=0\\), \\(m_2=0\\), and \\(l=0\\). </li> </ul> <ol> <li> <p>The variation consists of summarizing all contributions in the     stack to a single contribution as far as treatment of the     statistical uncertainties is concerned.\u00a0\u21a9</p> </li> </ol>"},{"location":"chapters/2.1.2_composite_distributions/","title":"Composite Distributions","text":""},{"location":"chapters/2.1.2_composite_distributions/#composite-distributions","title":"Composite distributions","text":"<p>This section contains composite distributions in the sense that they refer to other distribution which they combine or modify in some way.  The of the mixture distribution, sometimes called additions of distributions, is a (weighted) sum of distributions \\(f_i(\\vec{x})\\), depending on the same variable(s) \\(\\vec{x}\\): </p>"},{"location":"chapters/2.1.2_composite_distributions/#mixture-distribution","title":"Mixture distribution","text":"\\[ \\begin{aligned} \\text{MixturePdf}(x) = \\frac{1}{\\ensuremath{\\mathcal{M}}}\\sum_{i=1}^{n} c_i \\cdot f_i(\\vec{x}) , \\end{aligned}  \\] <p>where the \\(c_i\\) are coefficients and \\(\\vec{x}\\) is the vector of variables. </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>mixture_dist</code> </li> <li><code>name</code>: name of the variable \\(x\\) (optional, since the     variable is fully defined by the summands) </li> <li><code>summands</code>: array of names referencing distributions </li> <li><code>coefficients</code>: array of names of coefficients \\(c_i\\) or numbers to     be added </li> <li><code>extended</code>: boolean denoting whether this is an extended     distribution (optional, as it can be inferred from the     lengths of the lists for <code>summands</code> and <code>coefficients</code>)  This distribution can be treated as extended or as non-extended. </li> <li>If the number of coefficients equals the number of distributions and     'extended' is 'false', then the sum of the coefficient must be     (approximately) one. </li> <li>If the number of coefficients equals the number of distributions and     'extended' is 'true', then the sum of the coefficients will be used     as the Poisson rate parameter and the mixture distribution itself     will use the coefficients normalized by their sum. </li> <li>If the number of coefficients is one less than the number of     distributions, then 'extended' must be 'false' and \\(c_n\\) is computed     from the other coefficients as </li> </ul> \\[ \\begin{aligned}     c_n &amp;= 1 - \\sum_{i=1}^{n-1}c_i .     \\end{aligned}  \\]"},{"location":"chapters/2.1.2_composite_distributions/#sec:product-distribution","title":"Product distribution","text":"<p>The of the product of s of independent distributions \\(f_i\\) is defined as </p> \\[ \\begin{aligned} \\text{ProductPdf}(x) &amp;= \\frac{1}{\\ensuremath{\\mathcal{M}}}\\prod_i^n f(x). \\end{aligned}  \\] <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>product_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) (optional, since the     variable is fully defined by the factors) </li> <li><code>factors</code>: array of names referencing distributions  A distribution that is specified via a non-normalized density function \\(f(x)\\). Formally, it corresponds to the probability measure that has the density \\(f(x)\\) in respect to the Lebesgue measure.  The density function is normalized automatically by \\(\\ensuremath{\\mathcal{M}}= \\int f(x) dx\\), so the PDF of the distribution is </li> </ul>"},{"location":"chapters/2.1.2_composite_distributions/#density-function-distribution","title":"Density Function distribution","text":"\\[ \\begin{aligned} \\text{DensityFunctionPdf}(f, x) &amp;= \\frac{f(x)}{\\ensuremath{\\mathcal{M}}} \\end{aligned}  \\] <p>The distribution can be specified either via the non-normalized density function \\(f(x)\\) or via the non-normalized log-density function \\(\\log(f(x))\\): </p> <ul> <li><code>density_function\\_dist</code>$: Specified via the PDF \\(f(x)\\) </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>density_function_dist</code> </li> <li><code>function</code>: The density function \\(f\\) </li> <li><code>log_density_function\\_dist</code>: Specified via the PDF     \\(f(x)\\) </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>log_density_function_dist</code> </li> <li><code>function</code>: The density function \\(f\\) </li> </ul>"},{"location":"chapters/2.1.2_composite_distributions/#dist:poisson-point-process","title":"Poisson point process","text":"<p>A Poisson point process distribution is understood here as the distribution of the outcomes of a (typically inhomogeneous) Poisson point process. In particle physics, such a distribution is often called an extended distribution [^barlow-extended-ml].  In HS<sup>3</sup>, a Poisson point process distribution is specified using a global-rate parameter \\(\\lambda\\) and an underlying distribution \\(m\\), either explicitly or implicitly (see below).  Random values are drawn from the Poisson point process distribution by drawing a random number \\(n\\) from a Poisson distribution of the global-rate \\(\\lambda\\), and then drawing \\(n\\) random values from the underlying distribution \\(m\\). The resulting random values are vectors \\(x\\) of length \\(n\\), so their length varies.  The PDF the Poisson point process distribution at an outcome \\(x\\) (a vector of length \\(n\\)) is </p> \\[ \\begin{aligned} \\text{PoissonPointProcessPdf}(\\lambda, m, x) &amp;= \\text{PoissonPdf}(n, \\lambda) \\cdot \\prod_i^n \\text{PDF}(m, x_i). \\end{aligned}  \\] <p>In particle physics, the function \\(\\text{PoissonPointProcessPdf}(\\lambda, m(\\theta), x)\\), for a fixed observation \\(x\\) and varying parameters \\(\\lambda\\) and \\(\\theta\\), is often called an extended likelihood.  A a poisson point process distribution can be specified in HS<sup>3</sup> in two ways: </p> <ul> <li>`rate_extended_dist$: The global-rate parameter \\(\\lambda\\)     and underlying distribution \\(m\\) are specified explicitly: </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>rate_extended_dist</code> </li> <li><code>rate</code>: The global rate \\(\\lambda\\) </li> <li><code>dist</code>: The underlying distribution \\(m\\) </li> </ul> <p>The name of the variable \\(x\\) is taken from the underlying     distribution. The underlying distribution must not be     referred to from other components of the statistical model. </p> <ul> <li><code>rate_density_dist</code>: Specified via a non-normalized     rate-density function \\(f\\). Both the global-rate parameter and the     underlying distribution are implicit: \\(\\lambda = \\int f(y) d y\\) and     \\(m = \\text{density_function_dist}(f)\\). More formally, the distribution corresponds to the inhomogeneous     Poisson point process that is defined by a non-normalized rate     measure which has density \\(f\\) in respect to the Lebesque measure. </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>rate_density_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>density</code>: The rate-density function \\(f\\) </li> </ul>"},{"location":"chapters/2.1.2_composite_distributions/#dist:bin-counts","title":"Bin count distribution","text":"<p>This is a binned version of the Poisson point process distribution  (Poisson point process). Is is the distribution of the bin counts that result from histogramming the outcomes of a Poisson point process distribution using a given binning scheme (see  Binned Data).  Like the Poisson point process distribution, a Bin-counts distribution can either be specified via a global-rate parameter \\(\\lambda\\) and an underlying distribution \\(m\\), or via a rate-density function \\(f\\) (in which case \\(\\lambda\\) and \\(m\\) are implicit). In addition, the binning scheme also has to be specified in either case, unless it can be inferred (see below).  For \\(k\\) bins, this type of distribution corresponds to a product of \\(k\\) Poisson distributions with rates </p> \\[ \\begin{aligned} \\nu_i &amp;= \\lambda \\cdot \\int_{\\text{bin}_i} \\text{PDF}(y, m) dy \\quad \\text{equivalent to}\\\\ \\nu_i &amp;= \\int_{\\text{bin}_i} f(y) dy \\end{aligned}  \\] <p>The PDF the Bin-counts distribution at an outcome \\(x\\) (a vector of length \\(k\\), same as the number of bins) is </p> \\[ \\begin{aligned} \\text{BinCountsPdf}(x) &amp;= \\prod_i^k \\text{PoissonPdf}(x_i, \\nu_i) \\end{aligned}  \\] <ul> <li><code>bincounts_extended_dist</code>: The global-rate parameter     \\(\\lambda\\) and underlying distribution \\(m\\) are specified explicitly: </li> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>bincounts_extended_dist</code> </li> <li><code>rate</code>: The global rate \\(\\lambda\\) </li> <li><code>dist</code>: The underlying distribution \\(m\\) </li> <li><code>axes</code>: a definition of the binning to be used, following the         defintions in      Binned data]. optional if <code>dist</code>         is a binned distribution, in which case the same binning is used         by default. </li> </ul> <p>The name of the variable \\(x\\) is taken from the underlying     distribution. The underlying distribution must not be     referred to from other components of the statistical model.  <code>bincounts_density_dist</code>: Specified via a non-normalized     rate-density function \\(f\\). Both the global-rate parameter and the     underlying distribution are implicit: \\(\\lambda = \\int f(y) dy\\) and     \\(m = \\text{density_function_dist}(f)\\). </p> <p>More formally, the distribution corresponds to the inhomogeneous     Poisson point process that is defined by a non-normalized rate     measure which has density \\(f\\) in respect to the Lebesque measure. </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>bincounts_density_dist</code> </li> <li><code>x</code>: name of the variable \\(x\\) </li> <li><code>density</code>: The rate-density function \\(f\\) </li> <li><code>axes</code>: a definition of the binning to be used, following the         defintions in          Binned Data. </li> </ul>"},{"location":"chapters/2.1_distributions/","title":"Distributions","text":""},{"location":"chapters/2.1_distributions/#sec:distributions","title":"Distributions","text":"<p>The top-level component <code>distributions</code> contains an array of distributions in struct format. Distributions must be normalized, thus, the letter \\(\\ensuremath{\\mathcal{M}}\\) in the following descriptions will always relate to the normalization of the distribution. The value of \\(\\ensuremath{\\mathcal{M}}\\) is conditional on the current domain. It must be chosen such that the integral of the distribution over the current domain equals one. The implementations might chose to perform this integral using analytical or numerical means.  Each distribution must have the components <code>type</code>, denoting the kind of distribution described, and a component <code>name</code>, which acts as a unique identifier of this distribution among all other named objects. Distributions in general have the following keys:  -   <code>name</code>: custom unique string (required), e.     g.\u00a0<code>my_distribution_of_x</code>  -   <code>type</code>: string (required) that determines the kind of     distribution, e. g.\u00a0<code>gaussian_dist</code>  -   <code>...</code>: each distribution may have components for the     various individual parameters. For example, distributions of type     <code>gaussian_dist</code> have the specific components <code>mean</code>, <code>sigma</code> and     <code>x</code>. In general, these components may be strings as     references to other <code>objects</code>, but may also directly     yield numeric or boolean values. Depending on the parameter and the     type of distribution, they appear either in single item or array     format. </p> Example: Distributions<pre><code>\"distributions\":[\n    { \"name\":\"gauss1\", \"type\":\"gaussian_dist\", \"mean\":1.0, \"sigma\":\"param_sigma\", \"x\":\"param_x\" }, \n    { \"name\":\"exp1\", \"type\":\"exponential_dist\", \"c\":-2, \"x\":\"data_x\" }, \n    ... \n] \n</code></pre> <p>Distributions can be treated either as <code>extended</code> or as non-<code>extended</code> [^barlow-extended-ml]. Some distributions are always extended, others can never be extended, yet others can be used in extended and non-extended scenarios and have a switch selecting between the two. An non-extended distribution is always normalized to the unity. An extended distribution, on the other hand, can yield values larger than unity, where the yield is interpreted as the number of predicted events. That is to say, the distribution is augmented by a factor that is a Poisson constraint term for the total number of events.  In the following, all distributions supported in HS<sup>3</sup> v0.2.9 are listed in detail. Future versions will expand upon this list. </p>"},{"location":"chapters/2.2_functions/","title":"Functions","text":""},{"location":"chapters/2.2_functions/#sec:functions","title":"Functions","text":"<p>The top-level component <code>functions</code> describes an array of mathematical functions in struct format to be used as helper objects. Similar to distributions each entry is required to have the components <code>type</code> and <code>name</code>. Other components are dependent on the kind of functions. The field <code>name</code> is required and may be any custom unique string. Functions in general have the following components: </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: string that determines the kind of function, e.g. <code>sum</code> </li> <li><code>...</code>: each function has individual parameter keys for the various     individual parameters. For example, functions of type <code>sum</code> have the     parameter key <code>summands</code>. In general, these keys can describe     strings as references to other objects or numbers. Depending on the     parameter and the type of function, they appear either in single     item or array format. </li> </ul> Example: Functions<pre><code>\"functions\": [ \n    { \"name\" : \"sum1\", \"type\" : \"sum\", \"summands\" : [1.8, 4, \"param_xy\"] }, \n    ... \n    ]\n</code></pre> <p>In the following the implemented functions are described in detail. </p>"},{"location":"chapters/2.2_functions/#product","title":"Product","text":"<p>A product of values or functions \\(a_i\\). </p> \\[ \\begin{aligned} \\text{Prod} &amp;= \\prod_i^n a_i \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>product</code> </li> <li><code>factors</code>: array of names of the elements of the product or numbers. </li> </ul>"},{"location":"chapters/2.2_functions/#sum","title":"Sum","text":"<p>A sum of values or functions \\(a_i\\). </p> \\[ \\begin{aligned} \\text{Sum} &amp;= \\sum_i^n a_i \\end{aligned}  \\] <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>sum</code> </li> <li><code>summands</code>: array of names of the elements of the sum or numbers. </li> </ul>"},{"location":"chapters/2.2_functions/#generic-function","title":"Generic Function","text":"<p>Note: Users should prefer the specific functions defined in this standard over generic functions where possible, as implementations of these will typically be more optimized. Generic functions should only be used if no equivalent specific distribution is defined.  A generic function is defined by an expression. The expression must be a valid HS<sup>3</sup>-expression string (see Section  Generic Expressions). </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>generic_function</code> </li> <li><code>expression</code>: a string with a generic mathematical expression.     Simple mathematical syntax common to programming languages should be     used here, such as <code>x-2*y+z</code>. For any non-elementary operations, the     behavior is undefined. </li> </ul>"},{"location":"chapters/2.3_data/","title":"Data","text":""},{"location":"chapters/2.3_data/#sec:data","title":"Data","text":"<p>The top-level component <code>data</code> contains an array of data sets in struct format. Each data set needs to contain the components <code>type</code> and <code>name</code>. Other components are dependent on the type of data set as demonstrated below: </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: string that determines the format of the observations </li> <li><code>...</code>: each type of observations has different parameter keys. Some     of these are optional and marked accordingly in the     more detailed description below  A detailed description of the different types with examples can be found below.  While data, in most settings, has no uncertainty attached to it, this standard does allow to provide data with uncertainty, as there are some settings in which uncorrelated or correlated errors need to be taken into account. These include cases such as </li> <li>generated data obtained from importance sampling, including a     (potentially Gaussian) uncertainty from the frequency weights </li> <li>unfolded data, resulting from arbitrarily complex transformation     functions involving statistical models folding some degree of     uncertainty into the data points themselves  While it should always be preferred to publish \"raw\" data, allowing to include pre-processed data with corresponding uncertainties expands the possible applications considerably. </li> </ul>"},{"location":"chapters/2.3_data/#point-data","title":"Point Data","text":"<p>Point data describes a measurement of a single number, with a possible uncertainty (error). </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>point</code> </li> <li><code>value</code>: value of this data point </li> <li><code>uncertainty</code>: (optional) uncertainty of this data     point </li> </ul> Example: Point Data<pre><code>\"data\":[ \n    { \n        \"name\":\"data1\", \n        \"type\":\"point\", \n        \"value\":0., \n        \"uncertainty\":1. \n    } \n]\n</code></pre>"},{"location":"chapters/2.3_data/#unbinned-data","title":"Unbinned Data","text":"<p>Unbinned data describes a measurement of multiple data points in a possibly multi-dimensional space of variables. These data points can be weighted. </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>unbinned</code> </li> <li><code>entries</code>: array of arrays containing the coordinates/entries of the     data </li> <li><code>axes</code>: array of structs representing the axes. Each struct     must have the components <code>name</code> as well as <code>max</code> and     <code>min</code>. </li> <li><code>weights</code>: (optional) array of values containing the     weights of the individual data points, to be used for \\(\\chi^2\\)     comparisons and fits. If this component is not given, weight 1 is     assumed for all data points. If given, the array needs to be of the     same length as <code>entries</code>. </li> <li><code>entries_uncertainties</code>: (optional) array of arrays     containing the errors/uncertainties of each entry. If given, the     array needs to be of the same shape as <code>entries</code>.  Example: Unbinned Data<pre><code>\"data\":[ \n    { \n        \"name\":\"data1\", \n        \"type\":\"unbinned\", \n        \"weights\":[ 9.0, 18.4 ], \n        \"entries\":[ [1,3], [2,9] ], \n        \"entries_uncertainties\":[ [0.3], [0.6] ], \n        \"axes\":[ \n            { \"name\":\"variable1\", \"min\":1, \"max\":3 }, \n            { \"name\":\"variable2\", \"min\":-10, \"max\":10 }, \n            ... \n        ] \n    }, \n    ... \n]\n</code></pre></li> </ul>"},{"location":"chapters/2.3_data/#sec:binned-data","title":"Binned Data","text":"<p>Binned data describes a histogram of data points with bin contents in a possibly multi-dimensional space of variables. Whether entries that fall precisely on the bin boundaries are sorted into the smaller or larger bin is under the discretion of the creator of the model and thus not defined. </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>binned</code> </li> <li><code>contents</code>: array of values representing the contents of the binned     data set </li> <li><code>axes</code>: array of structs representing the axes. Each struct     must have the component <code>name</code>. Further, it must     specify the binning through one of these two options: <ol> <li>regular binnings are specified through the components <code>max</code>,         <code>min</code> and <code>nbins</code> </li> <li>potentially irregular binnings are specified through the         component <code>edges</code>, which contains an array of length \\(n+1\\),         where the first and last entries denote the minimum and and         maximum of the variable, and all entries between denote the         intermediate bin boundaries. </li> </ol> </li> <li><code>uncertainty</code>: (optional) struct representing the     uncertainty of the contents. It consists of up to three components: <ul> <li><code>type</code>: denoting the kind of uncertainty, for now only Gaussian         distributed uncertainties denoted as <code>gaussian_uncertainty</code> are         supported </li> <li><code>sigma</code>: array of the standard deviation of the entries in         <code>contents</code>. Needs to be of the same length as <code>contents</code> </li> <li><code>correlation</code>: (optional) array of arrays denoting         the correlation between the contents in matrix format. Must be         of dimension length of <code>contents</code> \\(\\times\\) length of <code>contents</code>.         It can also be set to 0 to indicate no correlation. </li> </ul> </li> </ul> Example: Binned Data<pre><code>\"data\":[ \n    { \n        \"name\":\"data2\", \n        \"type\":\"binned\", \n        \"contents\":[ 9.0, 18.4 ], \n        \"axes\":[ { \"name\":\"variable1\", \"nbins\":2, \"min\":1, \"max\":3 } ] \n    }, \n    { \n        \"name\":\"asimov_data2\",\n        \"type\":\"binned\", \n        \"contents\":[ 9.0, 18.4, 13, 0. ], \n        \"axes\":[ { \"name\":\"variable1\", \"nbins\":2, \"min\":1, \"max\":3 }, { \"name\":\"variable2\", \"edges\"[0,10,100] } ] \n    }, \n    ... \n    ]\n</code></pre> <p>This type can also be used to store pre-processed data utilizing the <code>uncertainty</code> component </p> Example: Pre-processed binned Data<pre><code>\"data\":[ \n    { \n        \"name\":\"data4\", \n        \"type\":\"binned\", \n        \"contents\":[ 9.0, 18.4 ], \n        \"uncertainty\" : { \n            \"type\": \"gaussian_uncertainty\", \n            \"correlation\" : 0, \n            \"sigma\" : [ 3, 4 ]\n        }, \n        \"axes\":[ \n            { \"name\":\"variable1\", \"nbins\":2, \"min\":1, \"max\":3 }, \n            ... \n        ] \n    }, \n    ... \n    ] \n</code></pre>"},{"location":"chapters/2.4_likelihoods/","title":"Likelihoods","text":""},{"location":"chapters/2.4_likelihoods/#sec:likelihoods","title":"Likelihoods","text":"<p>The top-level component <code>likelihoods</code> contains an array of likelihoods in struct format specifying mappings of distributions and observations. The corresponding distributions and observations are inserted as keys in string format referencing to distributions and observations defined in the respective top-level components, or as numbers for fixed data values.  The combination of parameterized distributions \\(m_i(\\theta_i)\\) with observations \\(x_i\\) generates a likelihood function </p> \\[ \\begin{aligned} \\ensuremath{\\mathscr{L}}(\\theta_1, \\theta_2, \\ldots) &amp;=  \\prod_i \\text{PDF}(m_i(\\theta_i), x_i) \\end{aligned}  \\] <p>The components of a likelihood struct are: </p> <ul> <li><code>name</code>: custom string </li> <li><code>distributions</code>: array of strings referencing the considered     distributions </li> <li><code>data</code>: array of strings referencing the used data, must be of the     same length as the array of <code>distributions</code>. Alternatively, the     data-values for single-dimensional distributions can be given     in-line. For example, this can be used for constraint terms     representing auxiliary measurements. </li> <li><code>aux_distributions</code>: (optional) array of strings     referencing the considered auxiliary distributions defined in the     top-level component <code>distributions</code>. They can be used to encode     regularizers or penalty terms to aid the minimization. These     observed data for these distributions is implicit and not part of     <code>data</code>. </li> </ul> Example: Likelihoods<pre><code>\"likelihoods\":[ \n    { \n        \"name\":\"likelihood1\", \n        \"distributions\":[ \"dist1\", \"dist2\", \"single_dimensional_dist_1\", ... ], \n        \"data\":         [ \"data1\", \"data2\",                           0, ... ], \n        \"aux_distributions\" : [ \"regularization_term\" ] }, \n        ... \n    ] \n</code></pre>"},{"location":"chapters/2.5_domains/","title":"Domains","text":""},{"location":"chapters/2.5_domains/#sec:domains","title":"Domains","text":"<p>The top-level component <code>domains</code> contains an array of domains giving information on the ranges of parameters and variables in struct format. Within a specified domain, the corresponding model is expected to yield valid values. Each domain must contain a <code>name</code> and a <code>type</code> although right now only the <code>product_domain</code> type is supported, even though others like e. g.\u00a0a simplex domain might be added later. A domain consists of the following components: </p> <ul> <li><code>name</code>: custom string </li> <li><code>type</code>: <code>product_domain</code> </li> <li><code>axes</code>: array of parameters and variables in this domain (see below)  The component <code>axes</code> itself is an array of ranges each containing the components <code>min</code>, <code>max</code> and <code>name</code>. </li> <li><code>name</code>: custom string </li> <li><code>max</code>: upper bound of range </li> <li><code>min</code>: lower bound of range </li> </ul> Example: Domains<pre><code>\"domains\":[ \n    { \n        \"name\":\"domain1\", \n        \"type\":\"product_domain\", \n        \"axes\": [ \n            { \"name\" : \"par_1\", \"max\" : 1, \"min\" : 8 }, \n            { \"name\" : \"par_2\", \"max\" : 4.78, \"min\" : 6 }, \n            ... \n            ] \n    }, \n    ... \n]\n</code></pre>"},{"location":"chapters/2.6_parameter_points/","title":"Parameter Points","text":""},{"location":"chapters/2.6_parameter_points/#sec:parameterpoints","title":"Parameter points","text":"<p>The top-level component <code>parameter_points</code> contains an array of parameter configurations. These can be starting values for minimizations, parameter settings used to generate toy data, best-fit-values obtained, or points in parameter space used for different purposes. </p> <ul> <li><code>name</code>: custom string </li> <li><code>parameters</code>: array of parameter structs (see below)  The component <code>parameters</code> is an array of components each containing: </li> <li><code>name</code>: custom string </li> <li><code>value</code>: number, value of variable </li> <li><code>const</code>: (optional) boolean, whether variable is     constant or not. Default is <code>false</code>. </li> </ul> Example: Parameter points<pre><code>\"parameter_points\":[ \n    { \n        \"name\" : \"starting_values\", \n        \"parameters\": [ \n            { \"name\" : \"par_1\", \"value\": 3 }, \n            { \"name\" : \"par_2\", \"value\": 7, \"const\": true }, \n            ... \n            ] \n    }, \n    ... \n] \n</code></pre>"},{"location":"chapters/2.7_analyses/","title":"Analyses","text":""},{"location":"chapters/2.7_analyses/#sec:analyses","title":"Analyses","text":"<p>The top-level component <code>analyses</code> contains an array of possible (automated) analyses. To that extent, likelihoods, parameters of interest and the affiliated domains are listed. Description of the components: </p> <ul> <li><code>name</code>: long custom string </li> <li><code>likelihood</code>: name as reference to a likelihood defined in the top-level component <code>likelihoods</code> </li> <li><code>parameter_of_interest</code>: (optional) array of names as reference to parameters that are interesting for the analysis at hand </li> <li><code>domain</code>: name of a domain to be used for the parameters, defined in the top-level component <code>domains</code> </li> <li><code>init</code>: (optional) name of an initial value to be used, defined in the top-level component <code>parameter_points</code> </li> <li><code>prior</code>: (optional) name of a prior distribution, defined in the top-level component <code>distributions</code>. This is only used for Bayesian interpretations and should not be confused with auxiliary distributions listed in the likelihood section. The prior could, for example, be a product distribution of all the individual priors. If for any parameter, both a prior and a parameter domain are given, the prior should be truncated to the given parameter domain. Otherwise, implicit flat priors over the given parameter domain are assumed. </li> </ul> <p>All parameters of all distributions in the likelihood must either be listed under the domain referenced, or set to <code>const</code> in the parameter point referenced. </p> Example: Analyses<pre><code>\"analyses\": [ \n    { \n        \"name\" : \"analysis1\", \n        \"likelihood\" : \"likelihood1\", \n        \"aux_likelihood_terms\" : [\"distribtion_1\", \"distribution_2\", ...] \n        \"parameters_of_interest\" : [\"param1\"], \n        \"domain\" : \"domain1\" , \n        \"init\" : \"starting_values\", \n        \"prior\" : \"prior_dist\" \n    }, \n    ... \n]\n</code></pre>"},{"location":"chapters/2.8_metadata/","title":"Metadata","text":""},{"location":"chapters/2.8_metadata/#sec:metadata","title":"Metadata","text":"<p>The top-level component <code>metadata</code> contains meta-information related to the creation of the file. The component <code>hs3_version</code> stores the HS\\(^3\\) version and is required for now. Overview of the components: </p> <ul> <li><code>hs3_version</code>: (required) HS\\(^3\\) version number as     String for reference </li> <li><code>packages</code>: (optional) array of structs defining     packages and their version number used in the creation of this file,     depicted with the components <code>name</code> and <code>version</code> respectively </li> <li><code>authors</code>: (optional) array of authors, either     individual persons, or collaborations </li> <li><code>publications</code>: (optional) array of document     identifiers of publications associated with this file </li> <li><code>description</code>: (optional) short abstract/description     for this file </li> </ul> Example: Metadata<pre><code>\"metadata\" : { \n    \"hs3_version\" : \"0.2.0\", \n    \"packages\" : [ { \"name\": \"ROOT\", \"version\": \"6.28.02\" } ], \n    \"authors\": [\"The ATLAS Collaboration\", \"The CMS Collaboration\"], \n    \"publications\": [\"doiABCDEFG\"]\n} \n</code></pre>"},{"location":"chapters/2.9_misc/","title":"Misc","text":""},{"location":"chapters/2.9_misc/#sec:misc","title":"Miscellaneous","text":"<p>The top-level component <code>misc</code> can contain arbitrary, user-created information in struct format. </p> Example: Miscellaneous<pre><code>\"misc\" : { \n    \"customkey1\" : \"custom information 1\" , \n    \"myPackage_internal\" : { \n        \"somekey\" : \"custom info only affecting myPackage\", \n        \"default_color_for_all_curves\" : \"fuchsia\" } \n    } \n</code></pre> <p>This top-level component is intended to store any and all additional information, including user- or backend-specific meta-information. Examples include, but are not limited to:  -   colors and styles for drawing distributions in this file  -   suggested settings for samplers or minimizers when working with the     distributions in this file  -   comments explaining design choices made when building the model in     this file  -   suggested names and paths for output files to be used by backends     working with this file </p>"},{"location":"chapters/2_toplevels/","title":"Top-level components","text":"<p>In the followingc the top-level <code>component</code>s of HS\\(^3\\) and their parameters/arguments are described. Each component is completely optional, but certain components may depend on other components, which should be provided in that case. The only exception is the component <code>metadata</code> containing the version of HS\\(^3\\), which is always required. The supported top-level components are </p> <ul> <li><code>distributions</code>: (optional) array of <code>object</code>s defining distributions </li> <li><code>functions</code>: (optional) array of <code>object</code>s defining mathematical functions </li> <li><code>data</code>: (optional) array of <code>objects</code> defining observed or simulated data </li> <li><code>likelihoods</code>: (optional) array of <code>object</code>s defining combinations of distributions and data </li> <li><code>domains</code>: (optional) array of <code>object</code>s defining domains, describing ranges of parameters </li> <li><code>parameter_points</code>: (optional) array of <code>object</code>s defining parameter points. These may be used as starting points for minimizations or to document best-fit-values or nominal truth values of datasets </li> <li><code>analyses</code>: (optional) array of <code>object</code>s defining suggested analyses to be run on the models in this file </li> <li><code>metadata</code>: required struct containing meta information; HS\\(^3\\) version number (required), authors, paper references, package versions, data/analysis descriptions (optional) </li> <li><code>misc</code>: (optional) struct containing miscellaneous information, e.g. optimizer settings, plotting colors, etc. </li> </ul> <p>In the following each of these are described in more detail with respect to their own structure. </p>"},{"location":"chapters/3.1_generic_expressions/","title":"Generic Expressions","text":""},{"location":"chapters/3.1_generic_expressions/#sec:generic_expression","title":"Generic Expressions","text":"<p>This section details the HS<sup>3</sup> generic expression language.  Expressions can be use to specify generic functions and generic distributions.  The implementations that support generic expression must support: </p> <ul> <li>Literal integer (format <code>1234</code>), boolean (format <code>TRUE</code> and <code>FALSE</code>)     and floating point (format <code>123.4</code>, <code>1.234e2</code> and <code>1.234E2</code>) values. </li> <li>Literal values for \\(\\pi\\) (<code>PI</code>) and Euler's number (<code>EULER</code>). </li> <li>The arithmetic operators addition (<code>x + y</code>), subtraction (<code>x - y</code>),     multiplication (<code>x * y</code>), division (<code>x / y</code>) and exponentiation     (<code>x^y</code>). </li> <li>The comparison operators approximately-equal (<code>x == y</code>),     exactly-equal (<code>x === y</code>), not-approximately-equal (<code>x != y</code>),     not-exactly-equal (<code>x !== y</code>), less-than (<code>x &lt; y</code>), less-or-equal     (<code>x &lt;= y</code>), greater-than (<code>x &gt;= y</code>) and greater-or-equal (<code>x &gt;= y</code>). </li> <li>The logical operators logical-inverse (<code>!a</code>), logical-and     (<code>a &amp;&amp; b</code>), logical-or (<code>a || b</code>), less-or-equal (<code>a &lt;= b</code>),     greater-than (<code>a &gt;= b</code>) and greater-or-equal (<code>a &gt;= b</code>). </li> <li>Round brackets to specify the order of operations. </li> <li>The ternary operator <code>condition ? result_if_true : result_if_false</code> </li> <li>The functions <ul> <li><code>exp(x)</code>: Euler's number raised to the power of <code>x</code> </li> <li><code>log(x)</code>: Natural logarithm of <code>x</code> </li> <li><code>sqrt(x)</code>: The square root of <code>x</code> </li> <li><code>abs(x)</code>: The absolute value of <code>x</code> </li> <li><code>pow(x, y)</code>: <code>x</code> raised to the power of <code>y</code> </li> <li><code>pow(x, y)</code>: <code>x</code> raised to the power of <code>y</code> </li> <li><code>min(x, y)</code>: minimum of <code>x</code> and <code>y</code> </li> <li><code>max(x, y)</code>: maximum of <code>x</code> and <code>y</code> </li> <li><code>sin(x)</code>: The sine of <code>x</code> </li> <li><code>cos(x)</code>: The cosine of <code>x</code> </li> <li><code>tan(x)</code>: The tangent of <code>x</code> </li> <li><code>asin(x)</code>: The inverse sin of <code>x</code> </li> <li><code>acos(x)</code>: The inverse cosine of <code>x</code> </li> <li><code>atan(x)</code>: The inverse tangent of <code>x</code> </li> </ul> </li> </ul> <p>Symbols not defined here refer to variables in the HS<sup>3</sup> model.  The operator precedence and associativity is acorrding to the common conventions.  Spaces between operators and operands are optional. There must be no space between a function name and the function arguments, spaces between function arguments are optional (<code>f(a, b)</code> and <code>f(a,b)</code> are correct but <code>f (a, b)</code> is not allowed). </p> <p>Division must be treated as floating-point division (i.e. <code>2/3</code> should be equivalent to <code>2.0/3.0</code>). </p> <p>The approximately-equal (<code>a == b</code>) and the not-approximately-equal operator (<code>a != b</code>), should compare floating-point numbers to within a small multiple of the unit of least precision.  The behavior of any functions and operators not listed above is not defined, they are reserved for future versions of this standard. Implementations may support additional functions and operators as experimental features, but their use is considered non-standard and results in non-portable and potentially non-forward-compatible HS<sup>3</sup> documents. </p>"},{"location":"chapters/3_supplementary/","title":"Supplementary Material","text":"<p>This section contains supplementary material referenced in section  [sec:toplevel] </p>"},{"location":"parts/histfactory/","title":"Histfactory","text":"<p>HistFactory [^hf] is a language to describe statistical models consisting only of \"histograms\" (which is used interchangeably with \"step-functions\" in this context). Each HistFactory distribution describes one \"channel\" or \"region\" of a binned measurement, containing a stack of \"samples\", i. e.\u00a0binned distributions sharing the same binning (step-functions describing the signal or background of a measurement). Such a HistFactory model is shown in Figure 1 (originally from  [^atlashzz]). Each of the contributions may be subject to <code>modifiers</code>. </p> <p> </p> <p>The prediction for a binned region is given as </p> \\[ \\begin{aligned} \\lambda(x)=\\sum_{s\\in\\text{samples}} \\left[ \\left( d_s(x) + \\sum_{\\delta\\in M_{\\delta}} \\delta(x,\\theta_\\delta) \\right) \\prod_{\\kappa\\in M_\\kappa} \\kappa(x,\\theta_\\kappa)   \\right] \\end{aligned}  \\] <p>Here \\(d_s(x)\\) is the prediction associated with the sample \\(s\\), a step function </p> \\[ \\begin{aligned} d_s(x) = \\chi^{y_s}_{b}(x) \\end{aligned}  \\] <p>In this section, \\(\\chi^{y_s}_{b}(x)\\) denotes a generic step function in the binning \\(b\\) such that \\(\\chi_{b}(x) = y_{s,i}\\), some constant, if \\(x\\in[b_i,b_{i+1})\\). The \\(y_{s,i}\\) in this case are the bin contents (yields) of the histograms.  The \\(M_\\kappa\\) are the multiplicative modifiers, the \\(M_\\delta\\) are the additive modifiers. Each of the modifiers is either multiplicative (\\(\\kappa\\)) or additive (\\(\\delta\\)). All samples and modifiers share the same binning \\(b\\).  The modifiers depend on a set of nuisance parameters \\(\\theta\\), where each modifier can only depend on one \\(\\theta_i\\), but the \\(\\theta_i\\) can take the form of vectors and the same \\(\\theta_i\\) can be shared by several modifiers. By convention, these are denoted \\(\\alpha\\) if they affect all bins in a correlated way, and \\(\\gamma\\) if they affect only one bin at a time. The types of modifiers are </p> <ul> <li>A uncorrelated shape systematic or <code>shapefactor</code> modifier is a     multiplicative modifier that scales each single bin by the value of     some independent parameter \\(\\gamma\\). Here, \\(\\theta_i=\\vec{\\gamma}\\),     where the length of \\(\\vec{\\gamma}\\) is equal to the number of bins in     this region. This type of modifier is sometimes called <code>shapesys</code>,     with some nuance in the meaning. However, both are synonymous in the     context of this standard. </li> <li>A correlated shape systematic or <code>histosys</code> modifier is an     additive modifier that adds or subtracts a constant step function     \\(\\chi^f\\), scaled with a single factor \\(\\alpha\\). The modifier     contains a <code>data</code> section, which contains the subsections     \\(\\texttt{hi}\\) and \\(\\texttt{lo}\\) that help to define the step     function \\(\\chi^f\\). They contain <code>contents</code>, which define the     bin-wise additions or subtractions for \\(\\alpha=1\\). Here,     \\(\\theta_i=\\alpha\\). </li> <li>A normalization systematic or <code>normsys</code> modifier is a     multiplicative modifier that scales the entire sample with the same     constant factor \\(f\\) that is a function of \\(\\alpha\\). The modifier     contains a <code>data</code> section, which contains the values \\(\\texttt{hi}\\)     and \\(\\texttt{lo}\\) that help to define \\(f\\). There are different     functional forms that can be chosen for \\(f\\). However, by convention     \\(f(\\alpha=0)=1\\), \\(f(\\alpha=+1)=\\)\"<code>hi</code>\" and     \\(f(\\alpha=-1)=\\)\"<code>lo</code>\". In this case, \\(\\theta_i=\\alpha\\). </li> <li>A normalization factor or <code>normfactor</code> modifier is a     multiplicative modifier that scales the entire sample in this region     with the value of the parameter \\(\\mu\\) itself. In this case,     \\(\\theta_i=\\mu\\). </li> <li>The <code>staterror</code> modifier is a shorthand for encoding uncorrelated     statistical uncertainties on the values of the step-functions, using     a variant<sup>1</sup> of the Barlow-Beeston Method [^barlowbeeston]. Here,     the relative uncertainty on the sum of all samples in this region     containing the <code>staterror</code> modifier is computed bin-by-bin. Then, a     constrained uncorrelated shape systematic (<code>shapesys</code>) is created,     encoding these relative uncertainties in the corresponding <code>Poisson</code>     (or <code>Gaussian</code>) constraint term. </li> </ul> <p>The different modifies and their descriptions are also summarized in the following table: </p> Type of Modifier Description Definition Free Parameters Number of Free Parameters <code>histosys</code> Correlated Shape systematic \\(\\delta(x,\\alpha) = \\alpha * \\chi_b^f\\) \\(\\alpha\\) 1 <code>normsys</code> Normalization systematic \\(\\kappa(x,\\alpha) = f(\\alpha)\\) \\(\\alpha\\) 1 <code>normfactor</code> Normalization factor \\(\\kappa(x,\\mu) = \\mu\\) \\(\\mu\\) 1 <code>shapefactor</code>, <code>staterror</code> Shape factor \\(\\kappa(x,\\vec{\\gamma}) = \\chi_b^{\\gamma}\\) \\(\\gamma_0\\), ..., \\(\\gamma_n\\) #bins <p>The <code>staterror</code> modifier is a special subtype of <code>shapefactor</code>, where the mean of the constraint is given as the sum of the predictions of all the samples carrying a <code>staterror</code> modifier in this bin.  The way modifiers affect the yield in the corresponding bin is subject to an interpolation function. The <code>overallsys</code> and <code>histosys</code> modifiers thus allow for an additional key <code>interpolation</code>, which identifies one of the following functions: </p> <ul> <li><code>lin</code>: \\(\\begin{cases}     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{high}} - y_{\\textit{nominal}}) \\text{ if } x\\geq0\\\\     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{nominal}} - y_{\\textit{low}}) \\text{ if } x&lt;0     \\end{cases}\\) </li> <li><code>log</code>: \\(\\begin{cases}     y_{\\textit{nominal}} \\cdot \\left(\\frac{y_{\\textit{high}}}{y_{\\textit{nominal}}}\\right)^x \\text{ if } x\\geq0\\\\     y_{\\textit{nominal}} \\cdot \\left(\\frac{y_{\\textit{low}}}{y_{\\textit{nominal}}}\\right)^{-x}\\text{ if } x&lt;0     \\end{cases}\\) </li> <li><code>parabolic</code>: \\(\\begin{cases}     y_{\\textit{nominal}} + (2s+d)\\cdot(x-1)+(y_{\\textit{high}} - y_{\\textit{nominal}}) \\text{ if } x&gt;1\\\\     y_{\\textit{nominal}} - (2s-d)\\cdot(x+1)+(y_{\\textit{low}} - y_{\\textit{nominal})}\\text{ if } x&lt;-1\\\\     s \\cdot x^2 + d\\cdot x  \\text{ otherwise}     \\end{cases}\\)\\     with     \\(s=\\frac{1}{2}(y_{\\textit{high}} + y_{\\textit{low}}) - y_{\\textit{nominal}}\\)     and \\(d=\\frac{1}{2}(y_{\\textit{high}} - y_{\\textit{low}})\\) </li> <li><code>poly6</code>: \\(\\begin{cases}     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{high}} - y_{\\textit{nominal}}) \\text{ if } x&gt;1\\\\     y_{\\textit{nominal}} + x \\cdot (y_{\\textit{nominal}} - y_{\\textit{low}}) \\text{ if } x&lt;-1\\\\     y_{\\textit{nominal}} + x \\cdot (S + x \\cdot A \\cdot (15 + x^2 \\cdot (3x^2-10))) \\text{ otherwise}     \\end{cases}\\)\\     with \\(S = \\frac{1}{2}(y_{\\textit{high}} - y_{\\textit{low}})\\) and     \\(A=\\frac{1}{16}(y_{\\textit{high}} + y_{\\textit{low}} - 2\\cdot y_{\\textit{nominal}})\\) </li> </ul> <p>Modifiers can be constrained. This is indicated by the component <code>constraint</code>, which identifies the type of the constraint term. In essence, the likelihood picks up a penalty term for changing the corresponding parameter too far away from its nominal value. The nominal value is, by convention, defined by the type of constraint, and is 0 for all modifiers of type <code>sys</code> (<code>histosys</code>, <code>normsys</code>) and is 1 for all modifiers of type <code>factor</code> (<code>normfactor</code>, <code>shapefactor</code>). The strength of the constraint is always such that the standard deviation of constraint distribution is \\(1\\). </p> <p>The supported constraint distributions, also called constraint types, are <code>Gauss</code> for a gaussian with unit width (a gaussian distribution with a variance of \\(1\\)), <code>Poisson</code> for a unit Poissonian (e.g. a continous Poissonian with a central value 1), or <code>LogNormal</code> for a unit LogNormal,. If a constraint is given, a corresponding distribution will be considered in addition to the <code>aux_likelihood</code> section of the likelihood, constraining the parameter to its nominal value. </p> <p>An exception to this is provided by the <code>staterror</code> modifier as described above, and the <code>shapesys</code> for which a Poissonian constraint is defined with the central values defined as the squares of the values defined in <code>vals</code>. </p> <p>The components of a HistFactory distribution are: </p> <ul> <li><code>name</code>: custom unique string </li> <li><code>type</code>: <code>histfactory_yield</code> </li> <li><code>axes</code>: array of structs representing the axes. If given each struct     needs to have the component <code>name</code>. Further,     (optional) components are <code>max</code>, <code>min</code> and <code>nbins</code>,     or, alternatively, <code>edges</code>. The definition of the axes follows the     format for binned data (see Section      Binned Data). </li> <li><code>samples</code>: array of structs containing the samples of this channel.     For details see below.  Struct of one sample: </li> <li><code>name</code>: (optional) custom string, unique within this     function </li> <li><code>data</code>: struct containing the components <code>contents</code> and <code>errors</code>,     depicting the data contents and their errors. Both components are     arrays of the same length. </li> <li><code>modifiers</code>: array of structs with each struct containing a     component <code>type</code> of the modifier, as well as a component <code>parameter</code>     (defining a string) or a component <code>parameters</code> (defining an array     of strings) relating to the name or names of parameters controlling     this modifier. Further (optional) components are     <code>data</code> and <code>constraint</code>, both depending on the type of modifier. For     details on these components, see the description above.  Two modifiers are correlated exactly if they share the same parameters as indicated by <code>parameter</code> or <code>parameters</code>. In such a case, it is mandatory that they share the same constraint term. If this is not the case, the behavior is undefined. </li> </ul> HistFactory<pre><code>{\n  \"name\": \"myAnalysisChannel\",\n  \"type\": \"histfactory_dist\",\n  \"axes\": [ { \"max\": 1.0, \"min\": 0.0, \"name\": \"myRegion\", \"nbins\": 2 } ],\n  \"name\":\"myChannel1\",\n  \"samples\": [\n           {  \"name\": \"mySignal\",\n              \"data\": { \"contents\": [ 0.5, 0.7 ], \"errors\": [ 0.1, 0.1 ] },\n          \"modifiers\": [\n                 { \"parameter\": \"Lumi\", \"type\": \"normfactor\" },\n                 { \"parameter\": \"mu_signal_strength\", \"type\": \"normfactor\" },\n                 { \"constraint\": \"Gauss\", \"data\": { \"hi\": 1.1, \"lo\": 0.9 }, \"parameter\": \"my_normalization_systematic_1\", \"type\": \"normsys\" },\n                 { \"constraint\": \"Poisson\", \"parameters\": [\"gamma_stat_1\",\"gamma_stat_2\"], \"type\": \"staterror\" },\n                 { \"constraint\": \"Gauss\", \"data\": { \"hi\": { \"contents\": [ -2.5, -3.1 ] }, \"lo\": { \"contents\": [ 2.2, 3.7 ] } }, \"parameter\": \"my_correlated_shape_systematic_1\", \"type\": \"histosys\" },\n                 { \"constraint\": \"Poisson\", \"data\": { \"vals\": [ 0.0, 1.2 ] }, \"parameter\": \"my_uncorrelated_shape_systematic_2\", \"type\": \"shapesys\" }\n                   ]\n           },\n               { \"name\": \"myBackground\" ... }\n         ]\n} \n</code></pre> <ol> <li> <p>The variation consists of summarizing all contributions in the     stack to a single contribution as far as treatment of the     statistical uncertainties is concerned.\u00a0\u21a9</p> </li> </ol>"}]}